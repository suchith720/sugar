{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd2ea74e-3076-4f28-92bd-f665792ad7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 03_download-amazon-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "596d1ee8-172a-4665-b049-db7d3c6661e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31851a4-aa2f-4cd9-848d-a9f108cfa803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import requests, os, gzip, json, scipy.sparse as sp, numpy as np, argparse\n",
    "from huggingface_hub import hf_hub_download\n",
    "from timeit import default_timer as timer\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a493b6-d658-4015-90d4-9fa505c23ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "OLD_AMAZON_URL = 'https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/'\n",
    "HF_CATEGORIES_URL = 'https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/raw/main/all_categories.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593fb424-4e5b-4823-bd60-3c1f125c47c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_urls_in_page(url):\n",
    "    response = requests.get(url)\n",
    "    assert response.status_code == 200, f'Invalid url: {url}'\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    return [link.get('href') for link in soup.find_all('a') if link.get('href').endswith('.gz')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4b007c-4a0b-4ca0-9491-f8f409d9ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_url(url, fname):\n",
    "    file_response = requests.get(url, stream=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        for chunk in file_response.iter_content(chunk_size=1024):\n",
    "            f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e295d3-541a-438c-950b-00a4ea6333cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_amazon_dataset_from_url(data_dir, dtype='meta'):\n",
    "    folder = 'product' if dtype == 'meta' else 'review'\n",
    "    data_dir = f'{data_dir}/{folder}'\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    url = f'{OLD_AMAZON_URL}/metaFiles2' if dtype == 'meta' else f'{OLD_AMAZON_URL}/categoryFiles'\n",
    "    file_links = get_urls_in_page(url)\n",
    "    for link in tqdm(file_links):\n",
    "        furl, fname = urljoin(url, link), os.path.join(data_dir, link)\n",
    "        download_url(furl, fname)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94fb64d7-e70a-4583-b187-55d44b229b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_hf_categories(data_dir):\n",
    "    fname = os.path.join(data_dir, 'all_categories.txt')\n",
    "    if not os.path.exists(fname): download_url(HF_CATEGORIES_URL, fname)\n",
    "    with open(fname, 'r') as f:\n",
    "        categories = f.read().split('\\n')[:-1]\n",
    "    return categories\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f47a3ed9-bb09-4fff-96d9-9c08959e6244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_amazon_dataset_from_hf(data_dir, dtype='meta'):\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    categories = get_hf_categories(data_dir)\n",
    "    fprefix = 'raw/meta_categories/meta_' if dtype == 'meta' else 'raw/review_categories/'\n",
    "    for category in tqdm(categories):\n",
    "        hf_hub_download(repo_id='McAuley-Lab/Amazon-Reviews-2023', filename=f'{fprefix}{category}.jsonl',\n",
    "                        repo_type=\"dataset\", local_dir=data_dir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a49b3944-56fd-4914-bbca-631d078f8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dfrom', type=str, required=True)\n",
    "    parser.add_argument('--dtype', type=str, required=True)\n",
    "    parser.add_argument('--cache_dir', type=str, required=True)\n",
    "    return parser.parse_args()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = timer()\n",
    "\n",
    "    args = parse_args()\n",
    "\n",
    "    if args.dfrom == 'url':\n",
    "        download_amazon_dataset_from_url(args.cache_dir, dtype=args.dtype)\n",
    "    elif args.dfrom == 'hf':\n",
    "        download_amazon_dataset_from_hf(args.cache_dir, dtype=args.dtype)\n",
    "    else:\n",
    "        raise ValueError(f'Invalid source of dataset: {args.dfrom}')\n",
    "\n",
    "    end_time = timer()\n",
    "    print(f'Time elapsed: {end_time-start_time:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a997514c-0b1e-4a27-a4bd-e9f4672f56e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
