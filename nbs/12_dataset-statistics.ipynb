{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496512d-9c5f-4867-986c-fd24e7c6e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7782aa-4027-4fab-804c-433f4211b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0705a845-9af3-44da-a4b1-9a70146c1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import scipy.sparse as sp, re, xclib.data.data_utils as du, numpy as np, pandas as pd, os\n",
    "from IPython.display import display\n",
    "from torch.utils.data import Dataset\n",
    "from termcolor import colored, COLORS\n",
    "\n",
    "from sugar.core import *\n",
    "from xcai.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f55a2-f1f9-484b-8168-1ac8f0ecddf5",
   "metadata": {},
   "source": [
    "## `UpdatedDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7063c54-cec2-4bd0-b095-32e5e54822a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "METADATA_CODE = {'category': 'cat', 'see_also': 'sal', 'hyper_link': 'hlk', 'videos': 'vid', 'images': 'img', \n",
    "                 'entity': 'ent', 'canonical': 'can', 'entity_canonical_category': 'ecc', 'entity_canonical': 'enc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a90ef9-70a0-4f03-970d-3cf670fcc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UpdatedDataset:\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data_info(data_dir, type, suffix=''):\n",
    "        if len(suffix): suffix = f'.{suffix}'\n",
    "        ids, txt = load_raw_file(f'{data_dir}/raw_data/{type}{suffix}.raw.csv')\n",
    "        return {'identifier':ids, 'input_text':txt}\n",
    "\n",
    "    @staticmethod\n",
    "    def load_lbl_info(data_dir, x_prefix, y_prefix):\n",
    "        ids, txt = load_raw_file(f'{data_dir}/raw_data/label.{x_prefix}-{y_prefix}.raw.csv')\n",
    "        return {'identifier':ids, 'input_text':txt}\n",
    "\n",
    "    @staticmethod\n",
    "    def load_metadata_info(data_dir, metadata_type, x_prefix, y_prefix, z_prefix):\n",
    "        ids, txt = load_raw_file(f'{data_dir}/raw_data/{metadata_type}.{x_prefix}-{y_prefix}-{z_prefix}.raw.csv')\n",
    "        return {'identifier':ids, 'input_text':txt}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_trn_tst_info(data_dir, suffix=''):\n",
    "        trn_info = UpdatedDataset.load_data_info(data_dir, 'train', suffix)\n",
    "        tst_info = UpdatedDataset.load_data_info(data_dir, 'test', suffix)\n",
    "        return trn_info, tst_info\n",
    "\n",
    "    @staticmethod\n",
    "    def load_main_matrix(data_dir, x_prefix, y_prefix, type):\n",
    "        if os.path.exists(f'{data_dir}/{type}_X_Y_{x_prefix}-{y_prefix}.npz'):\n",
    "            mat = sp.load_npz(f'{data_dir}/{type}_X_Y_{x_prefix}-{y_prefix}.npz')\n",
    "        else:\n",
    "            mat = du.read_sparse_file(f'{data_dir}/{type}_X_Y_{x_prefix}-{y_prefix}.txt')\n",
    "        return mat\n",
    "\n",
    "    @staticmethod\n",
    "    def get_labels(data_dir, x_prefix, y_prefix):\n",
    "        trn_mat = UpdatedDataset.load_main_matrix(data_dir, x_prefix, y_prefix, 'trn')\n",
    "        tst_mat = UpdatedDataset.load_main_matrix(data_dir, x_prefix, y_prefix, 'tst')\n",
    "        \n",
    "        lbl_info = UpdatedDataset.load_lbl_info(data_dir, x_prefix=x_prefix, y_prefix=y_prefix)\n",
    "        \n",
    "        return trn_mat, tst_mat, lbl_info\n",
    "\n",
    "    @staticmethod\n",
    "    def load_metadata_matrix(data_dir, x_prefix, y_prefix, z_prefix, main_type, metadata_type):\n",
    "        if os.path.exists(f'{data_dir}/{metadata_type}_{main_type}_X_Y_{x_prefix}-{y_prefix}-{z_prefix}.npz'):\n",
    "            mat = sp.load_npz(f'{data_dir}/{metadata_type}_{main_type}_X_Y_{x_prefix}-{y_prefix}-{z_prefix}.npz')\n",
    "        else:\n",
    "            mat = du.read_sparse_file(f'{data_dir}/{metadata_type}_{main_type}_X_Y_{x_prefix}-{y_prefix}-{z_prefix}.txt')\n",
    "        return mat\n",
    "\n",
    "    @staticmethod\n",
    "    def get_metadata(data_dir, metadata_type, x_prefix, y_prefix, z_prefix):\n",
    "        trn_mat = UpdatedDataset.load_metadata_matrix(data_dir, x_prefix, y_prefix, z_prefix, 'trn', metadata_type)\n",
    "        tst_mat = UpdatedDataset.load_metadata_matrix(data_dir, x_prefix, y_prefix, z_prefix, 'tst', metadata_type)\n",
    "        lbl_mat = UpdatedDataset.load_metadata_matrix(data_dir, x_prefix, y_prefix, z_prefix, 'lbl', metadata_type)\n",
    "        \n",
    "        meta_info = UpdatedDataset.load_metadata_info(data_dir, metadata_type, x_prefix, y_prefix, z_prefix)\n",
    "        \n",
    "        return trn_mat, tst_mat, lbl_mat, meta_info\n",
    "\n",
    "    @staticmethod\n",
    "    def load_datasets(data_dir, metadata_type, x_prefix, y_prefix, z_prefix):\n",
    "        trn_info, tst_info = UpdatedDataset.get_trn_tst_info(data_dir, x_prefix)\n",
    "        trn_mat, tst_mat, lbl_info = UpdatedDataset.get_labels(data_dir, x_prefix, y_prefix)\n",
    "    \n",
    "        main_trn_dset = MainXCDataset(trn_info, trn_mat, lbl_info)\n",
    "        main_tst_dset = MainXCDataset(tst_info, tst_mat, lbl_info)\n",
    "    \n",
    "        trn_meta_mat, tst_meta_mat, lbl_meta_mat, meta_info = UpdatedDataset.get_metadata(data_dir, metadata_type, x_prefix, y_prefix, z_prefix)\n",
    "    \n",
    "        trn_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], trn_meta_mat, lbl_meta_mat, meta_info)\n",
    "        tst_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], tst_meta_mat, lbl_meta_mat, meta_info)\n",
    "    \n",
    "        trn_dset = XCDataset(main_trn_dset, cat_meta=trn_meta_dset)\n",
    "        tst_dset = XCDataset(main_tst_dset, cat_meta=tst_meta_dset)\n",
    "    \n",
    "        return trn_dset, tst_dset\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98363dff-a26b-493c-a88d-9332e7c9aa93",
   "metadata": {},
   "source": [
    "## `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd33853-79ba-41f0-aee5-a033f38fd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Dataset:\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data_lbl_info(data_dir, type, encoding='utf-8'):\n",
    "        fname = f'{data_dir}/raw_data/{type}.raw'\n",
    "        ids, txt = load_raw_file(fname+'.csv', encoding=encoding) if os.path.exists(fname+'.csv') else load_raw_file(fname+'.txt', encoding=encoding)\n",
    "        return {'identifier':ids, 'input_text':txt}\n",
    "\n",
    "    @staticmethod\n",
    "    def load_metadata_info(data_dir, metadata_type, encoding='utf-8'):\n",
    "        fname = f'{data_dir}/raw_data/{metadata_type}.raw'\n",
    "        ids, txt = load_raw_file(fname+'.csv', encoding=encoding) if os.path.exists(fname+'.csv') else load_raw_file(fname+'.txt', encoding=encoding)\n",
    "        return {'identifier':ids, 'input_text':txt}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_trn_tst_info(data_dir, encoding='utf-8'):\n",
    "        trn_info = Dataset.load_data_lbl_info(data_dir, 'train', encoding)\n",
    "        tst_info = Dataset.load_data_lbl_info(data_dir, 'test', encoding)\n",
    "        return trn_info, tst_info\n",
    "\n",
    "    @staticmethod\n",
    "    def get_labels(data_dir, encoding='utf-8'):\n",
    "        trn_mat = du.read_sparse_file(f'{data_dir}/trn_X_Y.txt') if os.path.exists(f'{data_dir}/trn_X_Y.txt') else sp.load_npz(f'{data_dir}/trn_X_Y.npz')\n",
    "        tst_mat = du.read_sparse_file(f'{data_dir}/tst_X_Y.txt') if os.path.exists(f'{data_dir}/tst_X_Y.txt') else sp.load_npz(f'{data_dir}/tst_X_Y.npz')\n",
    "            \n",
    "        lbl_info = Dataset.load_data_lbl_info(data_dir, 'label', encoding)\n",
    "        \n",
    "        return trn_mat, tst_mat, lbl_info\n",
    "\n",
    "    @staticmethod\n",
    "    def get_metadata(data_dir, metadata_type, encoding='utf-8'):\n",
    "        trn_mat = du.read_sparse_file(f'{data_dir}/{metadata_type}_trn_X_Y.txt') if os.path.exists(f'{data_dir}/{metadata_type}_trn_X_Y.txt') else sp.load_npz(f'{data_dir}/{metadata_type}_trn_X_Y.npz')\n",
    "        tst_mat = du.read_sparse_file(f'{data_dir}/{metadata_type}_tst_X_Y.txt') if os.path.exists(f'{data_dir}/{metadata_type}_tst_X_Y.txt') else sp.load_npz(f'{data_dir}/{metadata_type}_tst_X_Y.npz')\n",
    "        lbl_mat = du.read_sparse_file(f'{data_dir}/{metadata_type}_lbl_X_Y.txt') if os.path.exists(f'{data_dir}/{metadata_type}_lbl_X_Y.txt') else sp.load_npz(f'{data_dir}/{metadata_type}_lbl_X_Y.npz')\n",
    "        \n",
    "        meta_info = Dataset.load_metadata_info(data_dir, metadata_type, encoding)\n",
    "        \n",
    "        return trn_mat, tst_mat, lbl_mat, meta_info\n",
    "\n",
    "    @staticmethod\n",
    "    def load_datasets(data_dir, metadata_type, encoding='utf-8'):\n",
    "        trn_info, tst_info = Dataset.get_trn_tst_info(data_dir, encoding)\n",
    "        trn_mat, tst_mat, lbl_info = Dataset.get_labels(data_dir, encoding)\n",
    "    \n",
    "        main_trn_dset = MainXCDataset(trn_info, trn_mat, lbl_info)\n",
    "        main_tst_dset = MainXCDataset(tst_info, tst_mat, lbl_info)\n",
    "    \n",
    "        trn_meta_mat, tst_meta_mat, lbl_meta_mat, meta_info = Dataset.get_metadata(data_dir, metadata_type, encoding)\n",
    "    \n",
    "        trn_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], trn_meta_mat, lbl_meta_mat, meta_info)\n",
    "        tst_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], tst_meta_mat, lbl_meta_mat, meta_info)\n",
    "    \n",
    "        trn_dset = XCDataset(main_trn_dset, cat_meta=trn_meta_dset)\n",
    "        tst_dset = XCDataset(main_tst_dset, cat_meta=tst_meta_dset)\n",
    "    \n",
    "        return trn_dset, tst_dset\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f204e61-12e8-45f6-a9de-6fbe4ef67982",
   "metadata": {},
   "source": [
    "## Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1c875-103e-4264-8530-634dc1d06331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "CODE_METADATA = {'cat':'Category', 'sal':'Seealso', 'hlk':'Hyperlink', 'vid':'Videos', 'img':'Images', \n",
    "                 'ent':'Entity', 'can':'Canonical', 'ecc':'Entity Canonical Category', 'enc':'Entity Canonical'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148017f-1745-41fa-9c42-98cb1073e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def matrix_stats(mat):\n",
    "    n_dat = mat.shape[0]\n",
    "    n_lbl = mat.shape[1]\n",
    "\n",
    "    num_dat_lbl = mat.getnnz(axis=0)\n",
    "    num_lbl_dat = mat.getnnz(axis=1)\n",
    "\n",
    "    avg_dat_lbl = num_dat_lbl.mean()\n",
    "    avg_lbl_dat = num_lbl_dat.mean()\n",
    "\n",
    "    max_dat_lbl = num_dat_lbl.max()\n",
    "    max_lbl_dat = num_lbl_dat.max()\n",
    "\n",
    "    zro_dat_lbl = np.sum(num_dat_lbl == 0)\n",
    "    zro_lbl_dat = np.sum(num_lbl_dat == 0)\n",
    "\n",
    "    stats_dict = {\n",
    "        f'# Entries' : n_dat,\n",
    "        f'# Features': n_lbl,\n",
    "        f'Avg. Entries per feature' : avg_dat_lbl,\n",
    "        f'Avg. Feature per entry'   : avg_lbl_dat,\n",
    "        f'Max. Entries per feature' : max_dat_lbl,\n",
    "        f'Max. Feature per entry'   : max_lbl_dat,\n",
    "        f'# Features without entry' : zro_dat_lbl,\n",
    "        f'# Entries without feature': zro_lbl_dat,\n",
    "    }\n",
    "    return stats_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff3855-fe20-48e3-bf3b-c1a2d856e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def main_dset_stats(dset):\n",
    "    return matrix_stats(dset.data_lbl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3402404-adca-4e06-954b-0a4de32ef08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def meta_dset_stats(dset):\n",
    "    dat_stats = matrix_stats(dset.data_meta)\n",
    "    dat_stats['Dataset'] = 'Query'\n",
    "    \n",
    "    lbl_stats = matrix_stats(dset.lbl_meta)\n",
    "    lbl_stats['Dataset'] = 'Label'\n",
    "\n",
    "    return [dat_stats, lbl_stats]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798bf2cf-1712-48f3-91d4-22f073133ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def dset_stats(dset):\n",
    "    stats = []\n",
    "    \n",
    "    main_stats = main_dset_stats(dset.data)\n",
    "    main_stats['Dataset'] = 'Main'\n",
    "    stats.append(main_stats)\n",
    "\n",
    "    for o in dset.meta.values():\n",
    "        meta_stats = meta_dset_stats(o)\n",
    "        for s in meta_stats: s['Dataset'] = f'{s[\"Dataset\"]} {CODE_METADATA[o.prefix]} Metadata'\n",
    "        stats.extend(meta_stats)\n",
    "\n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a4fad-34b8-4dcd-a954-43153b104bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def trn_tst_stats(trn_dset, tst_dset):\n",
    "    trn_stats = dset_stats(trn_dset)\n",
    "    for o in trn_stats: o['Split'] = 'Train'\n",
    "\n",
    "    tst_stats = dset_stats(tst_dset)\n",
    "    for o in tst_stats: o['Split'] = 'Test'\n",
    "\n",
    "    stats = trn_stats + tst_stats\n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61285a6-6a4e-483e-8596-8b60243f405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def print_stats(stats):\n",
    "    df = pd.DataFrame(stats).set_index(['Split', 'Dataset'])\n",
    "    with pd.option_context('display.precision', 2):\n",
    "        display(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31efabfa-62bf-460d-ab52-42b30929cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def print_dset_stats(trn_dset, tst_dset):\n",
    "    stats = trn_tst_stats(trn_dset, tst_dset)\n",
    "    print_stats(stats)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b08cbd-9b5f-40d8-aa2c-e1e47a32b854",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76def8-ba85-4d88-b092-36ac39cb237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TextDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dset, pattern='.*_text$'):\n",
    "        self.dset, self.pattern = dset, pattern\n",
    "        colors = list(COLORS.keys())\n",
    "        self.colors = [colors[i] for i in np.random.permutation(len(colors))]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        o = self.dset[idx]\n",
    "        return {k:v for k,v in o.items() if re.match(self.pattern, k)}\n",
    "\n",
    "    def show(self, idxs):\n",
    "        for idx in idxs:\n",
    "            for i,(k,v) in enumerate(self[idx].items()):\n",
    "                key = colored(k, self.colors[i], attrs=[\"reverse\", \"blink\"])\n",
    "                value = colored(f': {v}', self.colors[i])\n",
    "                print(key, value)\n",
    "            print()\n",
    "\n",
    "    def get_head_data(self, topk=10):\n",
    "        return np.argsort(self.dset.data.data_lbl.getnnz(axis=1))[:-topk:-1]\n",
    "\n",
    "    def get_tail_data(self, topk=10):\n",
    "        num = self.dset.data.data_lbl.getnnz(axis=1)\n",
    "        idx = np.argsort(num)\n",
    "        valid = (num > 0)[idx]\n",
    "        return idx[valid][:topk]\n",
    "        \n",
    "    def dump_txt(self, fname, idxs):\n",
    "        with open(fname, 'w') as file:\n",
    "            for idx in idxs:\n",
    "                for i,(k,v) in enumerate(self[idx].items()):\n",
    "                    file.write(f'{k}: {v}\\n')\n",
    "                file.write('\\n')\n",
    "            \n",
    "    def dump_csv(self, fname, idxs):\n",
    "        df = pd.DataFrame([self[idx] for idx in idxs])\n",
    "        df.to_csv(fname, index=False)\n",
    "\n",
    "    def dump(self, fname, idxs):\n",
    "        if fname.endswith('.txt'): \n",
    "            self.dump_txt(fname, idxs)\n",
    "        elif fname.endswith('.csv'): \n",
    "            self.dump_csv(fname, idxs)\n",
    "        else: \n",
    "            raise ValueError(f'Invalid file extension: {fname}')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453ce35-d1fc-43d1-9f26-6c238d36393d",
   "metadata": {},
   "source": [
    "## Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e4c6d-6a29-42ab-aee7-03e95ff7adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "PREFIX_METDATA = {'cat': 'category', 'hlk': 'hyper_link', 'sal': 'see_also'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b259f25-d81c-431f-b796-2c3d198885c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_labels(data_dir, trn_dset, tst_dset):\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    sp.save_npz(f'{data_dir}/trn_X_Y.npz', trn_dset.data.data_lbl)\n",
    "    sp.save_npz(f'{data_dir}/tst_X_Y.npz', tst_dset.data.data_lbl)\n",
    "\n",
    "    os.makedirs(f'{data_dir}/raw_data', exist_ok=True)\n",
    "\n",
    "    save_raw_file(f'{data_dir}/raw_data/train.raw.txt', trn_dset.data.data_info['identifier'], trn_dset.data.data_info['input_text'])\n",
    "    save_raw_file(f'{data_dir}/raw_data/test.raw.txt', tst_dset.data.data_info['identifier'], tst_dset.data.data_info['input_text'])\n",
    "    save_raw_file(f'{data_dir}/raw_data/label.raw.txt', trn_dset.data.lbl_info['identifier'], trn_dset.data.lbl_info['input_text'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56cdc25-d92f-4925-ad71-69adbc269da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_metadata(data_dir, trn_dset, tst_dset):\n",
    "    metadata_type = None\n",
    "    \n",
    "    for metadata in trn_dset.meta.keys():\n",
    "        metadata_type = PREFIX_METDATA[trn_dset.meta[metadata].prefix]\n",
    "        \n",
    "        sp.save_npz(f'{data_dir}/{metadata_type}_trn_X_Y.npz', trn_dset.meta[metadata].data_meta)\n",
    "        sp.save_npz(f'{data_dir}/{metadata_type}_tst_X_Y.npz', tst_dset.meta[metadata].data_meta)\n",
    "        sp.save_npz(f'{data_dir}/{metadata_type}_lbl_X_Y.npz', trn_dset.meta[metadata].lbl_meta)\n",
    "        \n",
    "        save_raw_file(f'{data_dir}/raw_data/{metadata_type}.raw.txt', trn_dset.meta[metadata].meta_info['identifier'], trn_dset.meta[metadata].meta_info['input_text'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07511b9-da03-4a1c-b19b-59cd2a9bb51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_dataset(data_dir, trn_dset, tst_dset):\n",
    "    valid_idx = np.where(trn_dset.data.data_lbl.getnnz(axis=1) > 0)[0]\n",
    "    trn_dset = trn_dset._getitems(valid_idx)\n",
    "\n",
    "    valid_idx = np.where(tst_dset.data.data_lbl.getnnz(axis=1) > 0)[0]\n",
    "    tst_dset = tst_dset._getitems(valid_idx)\n",
    "\n",
    "    save_labels(data_dir, trn_dset, tst_dset)\n",
    "    save_metadata(data_dir, trn_dset, tst_dset)\n",
    "\n",
    "    return trn_dset, tst_dset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb23a33-3366-463c-b5e7-eb5aa0ed1cc4",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5374de-8db2-4af1-973b-fef026580a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_updated_dataset(data_dir, save_dir, metadata_type, x_prefix, y_prefix, z_prefix, idxs, use_trn=True):\n",
    "    trn_dset, tst_dset = UpdatedDataset.load_datasets(data_dir, save_dir, metadata_type, x_prefix, y_prefix, z_prefix)\n",
    "    print_dset_stats(trn_dset, tst_dset)\n",
    "    \n",
    "    txt_dset = TextDataset(trn_dset if use_trn else tst_dset)\n",
    "    txt_dset.show(idxs)\n",
    "    \n",
    "    return trn_dset, tst_dset\n",
    "\n",
    "def show_dataset(data_dir, metadata_type, idxs, suffix='', use_trn=True):\n",
    "    trn_dset, tst_dset = Dataset.load_datasets(data_dir, metadata_type, suffix=suffix)\n",
    "    print_dset_stats(trn_dset, tst_dset)\n",
    "    \n",
    "    txt_dset = TextDataset(trn_dset if use_trn else tst_dset)\n",
    "    txt_dset.show(idxs)\n",
    "    \n",
    "    return trn_dset, tst_dset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087e30b-2b43-4ab7-b951-80a18a5b3049",
   "metadata": {},
   "source": [
    "## `__main__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcdf79f-5c91-48fc-9600-ada3745a09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_dir', type=str, required=True)\n",
    "    parser.add_argument('--save_dir', type=str, required=True)\n",
    "    parser.add_argument('--metadata_key', type=str, required=None)\n",
    "    parser.add_argument('--x_prefix', type=str, required=True)\n",
    "    parser.add_argument('--y_prefix', type=str, required=True)\n",
    "    parser.add_argument('--z_prefix', type=str, required=True)\n",
    "    return parser.parse_args()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f1e4f-fa00-40df-a777-8f8c6d89c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    trn_dset, tst_dset = UpdatedDataset.load_datasets(args.data_dir, args.save_dir, args.metadata_type, \n",
    "                                                      args.x_prefix, args.y_prefix, args.z_prefix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa8b0e-24ef-44bc-94fc-c371eb418165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef98589-8392-4abc-9479-26aaeba1c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/scai/phd/aiz218323/scratch/datasets/benchmarks/(mapped)LF-WikiSeeAlsoTitles-320K/'\n",
    "save_dir = '/home/scai/phd/aiz218323/scratch/datasets/wikipedia/20250123/LF-WikiSeeAlsoTitles-320K/'\n",
    "\n",
    "metadata_type = 'category'\n",
    "x_prefix, y_prefix, z_prefix = 'new', 'new', 'new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2a73e-89e4-4c5d-86c7-53cceb331a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dset, tst_dset = UpdatedDataset.load_datasets(save_dir, metadata_type, x_prefix, y_prefix, z_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979a055-96c3-42bd-b122-dab9f8fda457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a3a4c-22a5-481e-bd32-ef0790a8648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = '/home/scai/phd/aiz218323/scratch/datasets/benchmarks/20250123-LF-WikiSeeAlsoTitles-320K/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba0356-304a-41e0-8d36-98fc56b01bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dset, tst_dset = save_dataset(new_dir, trn_dset, tst_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf8756-fef3-4c23-93b0-0b49c2583f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b5413-c8b4-41ca-9f73-3cb14c93dbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th># Entries</th>\n",
       "      <th># Features</th>\n",
       "      <th>Avg. Entries per feature</th>\n",
       "      <th>Avg. Feature per entry</th>\n",
       "      <th>Max. Entries per feature</th>\n",
       "      <th>Max. Feature per entry</th>\n",
       "      <th># Features without entry</th>\n",
       "      <th># Entries without feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split</th>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Train</th>\n",
       "      <th>Main</th>\n",
       "      <td>1183189</td>\n",
       "      <td>1205595</td>\n",
       "      <td>2.57</td>\n",
       "      <td>2.62</td>\n",
       "      <td>4747</td>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query Category Metadata</th>\n",
       "      <td>1183189</td>\n",
       "      <td>1155247</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.09</td>\n",
       "      <td>65056</td>\n",
       "      <td>245</td>\n",
       "      <td>159691</td>\n",
       "      <td>102390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Category Metadata</th>\n",
       "      <td>1205595</td>\n",
       "      <td>1155247</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.60</td>\n",
       "      <td>25831</td>\n",
       "      <td>247</td>\n",
       "      <td>280544</td>\n",
       "      <td>420595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Test</th>\n",
       "      <th>Main</th>\n",
       "      <td>340278</td>\n",
       "      <td>1205595</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1075</td>\n",
       "      <td>150</td>\n",
       "      <td>758109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query Category Metadata</th>\n",
       "      <td>340278</td>\n",
       "      <td>1155247</td>\n",
       "      <td>1.49</td>\n",
       "      <td>5.06</td>\n",
       "      <td>17104</td>\n",
       "      <td>247</td>\n",
       "      <td>625513</td>\n",
       "      <td>24033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Category Metadata</th>\n",
       "      <td>1205595</td>\n",
       "      <td>1155247</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.60</td>\n",
       "      <td>25831</td>\n",
       "      <td>247</td>\n",
       "      <td>280544</td>\n",
       "      <td>420595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               # Entries  # Features  \\\n",
       "Split Dataset                                          \n",
       "Train Main                       1183189     1205595   \n",
       "      Query Category Metadata    1183189     1155247   \n",
       "      Label Category Metadata    1205595     1155247   \n",
       "Test  Main                        340278     1205595   \n",
       "      Query Category Metadata     340278     1155247   \n",
       "      Label Category Metadata    1205595     1155247   \n",
       "\n",
       "                               Avg. Entries per feature  \\\n",
       "Split Dataset                                             \n",
       "Train Main                                         2.57   \n",
       "      Query Category Metadata                      5.21   \n",
       "      Label Category Metadata                      3.75   \n",
       "Test  Main                                         0.82   \n",
       "      Query Category Metadata                      1.49   \n",
       "      Label Category Metadata                      3.75   \n",
       "\n",
       "                               Avg. Feature per entry  \\\n",
       "Split Dataset                                           \n",
       "Train Main                                       2.62   \n",
       "      Query Category Metadata                    5.09   \n",
       "      Label Category Metadata                    3.60   \n",
       "Test  Main                                       2.90   \n",
       "      Query Category Metadata                    5.06   \n",
       "      Label Category Metadata                    3.60   \n",
       "\n",
       "                               Max. Entries per feature  \\\n",
       "Split Dataset                                             \n",
       "Train Main                                         4747   \n",
       "      Query Category Metadata                     65056   \n",
       "      Label Category Metadata                     25831   \n",
       "Test  Main                                         1075   \n",
       "      Query Category Metadata                     17104   \n",
       "      Label Category Metadata                     25831   \n",
       "\n",
       "                               Max. Feature per entry  \\\n",
       "Split Dataset                                           \n",
       "Train Main                                        987   \n",
       "      Query Category Metadata                     245   \n",
       "      Label Category Metadata                     247   \n",
       "Test  Main                                        150   \n",
       "      Query Category Metadata                     247   \n",
       "      Label Category Metadata                     247   \n",
       "\n",
       "                               # Features without entry  \\\n",
       "Split Dataset                                             \n",
       "Train Main                                            0   \n",
       "      Query Category Metadata                    159691   \n",
       "      Label Category Metadata                    280544   \n",
       "Test  Main                                       758109   \n",
       "      Query Category Metadata                    625513   \n",
       "      Label Category Metadata                    280544   \n",
       "\n",
       "                               # Entries without feature  \n",
       "Split Dataset                                             \n",
       "Train Main                                             0  \n",
       "      Query Category Metadata                     102390  \n",
       "      Label Category Metadata                     420595  \n",
       "Test  Main                                             0  \n",
       "      Query Category Metadata                      24033  \n",
       "      Label Category Metadata                     420595  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_dset_stats(trn_dset, tst_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23752dcd-98a8-443f-9c9d-554317906cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31211865-0322-4406-a4a9-ce6b55ac01a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_dset = TextDataset(trn_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5ce34-645b-461b-aec9-1db15c3596b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{new_dir}/examples', exist_ok=True)\n",
    "\n",
    "idxs = np.random.permutation(trn_dset.n_data)[:1000]\n",
    "txt_dset.dump(f'{new_dir}/examples/random_train.txt', idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc2f72-b8d3-4592-8a08-354066aa8a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[7m\u001b[90mdata_input_text\u001b[0m \u001b[90m: Arithmetic mean\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[94mlbl2data_input_text\u001b[0m \u001b[94m: ['Fréchet mean', 'Generalized mean', 'Summary statistics', 'Standard deviation', 'Standard error of the mean', 'Sample mean and covariance', 'Inequality of arithmetic and geometric means']\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[30mcat2data_input_text\u001b[0m \u001b[30m: ['Means']\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[95mcat2lbl2data_input_text\u001b[0m \u001b[95m: [['Means'], ['Means', 'Inequalities', 'Articles with example Haskell code'], ['Summary statistics'], ['Summary statistics', 'Statistical deviation and dispersion'], [], ['U-statistics', 'Summary statistics', 'Estimation methods', 'Covariance and correlation', 'Matrices'], []]\u001b[0m\n",
      "\n",
      "\u001b[5m\u001b[7m\u001b[90mdata_input_text\u001b[0m \u001b[90m: Annual plant\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[94mlbl2data_input_text\u001b[0m \u001b[94m: ['Ephemeral plant']\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[30mcat2data_input_text\u001b[0m \u001b[30m: ['Annual plants']\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[95mcat2lbl2data_input_text\u001b[0m \u001b[95m: [['Ephemeral plants', 'Plants', 'Flowers']]\u001b[0m\n",
      "\n",
      "\u001b[5m\u001b[7m\u001b[90mdata_input_text\u001b[0m \u001b[90m: Audi\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[94mlbl2data_input_text\u001b[0m \u001b[94m: ['DKW', 'Wanderer (company)', 'Volkswagen Group', 'Horch']\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[30mcat2data_input_text\u001b[0m \u001b[30m: ['Companies based in Ingolstadt', 'Volkswagen Group', 'Re-established companies', 'Sports car manufacturers', 'Car manufacturers of Germany', 'Car brands', 'Companies based in Saxony', 'Companies based in Bavaria', 'Companies based in Baden-Württemberg', 'Vehicle manufacturing companies established in 1909', 'Vehicle manufacturing companies disestablished in 1939', 'German brands', 'Companies formerly listed on the Frankfurt Stock Exchange', 'Audi', 'Vehicle manufacturing companies established in 1965', 'German companies established in 1909', 'Luxury motor vehicle manufacturers']\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[95mcat2lbl2data_input_text\u001b[0m \u001b[95m: [['Volkswagen Group', 'DKW', 'Auto Union', 'Car brands', 'Motorcycle manufacturers of Germany', 'Vehicle manufacturing companies disestablished in 1966', 'Audi', 'Vehicle manufacturing companies established in 1916', 'Defunct motor vehicle manufacturers of Germany'], ['Vehicle manufacturing companies disestablished in 1945', 'Defunct motorcycle manufacturers of Germany', 'Vehicle manufacturing companies established in 1896', '1896 establishments in Germany', 'Auto Union', '1945 disestablishments in Germany', 'Defunct motor vehicle manufacturers of Germany'], ['1960s initial public offerings', 'German companies established in 1937', 'Volkswagen Group', 'Companies in the Euro Stoxx 50', 'Emergency services equipment makers', 'Multinational companies headquartered in Germany', 'Companies formerly listed on the London Stock Exchange', 'Companies involved in the Holocaust', 'Conglomerate companies of Germany', 'Conglomerate companies established in 1937', 'Motor vehicle engine manufacturers', 'Companies in the DAX index', 'Vehicle manufacturing companies established in 1937', 'Government-owned companies of Germany', 'Companies based in Lower Saxony', 'Companies listed on the Frankfurt Stock Exchange', 'Diesel engine manufacturers'], ['Vehicle manufacturing companies established in 1899', 'Zwickau', 'German companies established in 1899', '1932 disestablishments in Germany', 'Horch', 'Auto Union', 'Audi', 'Luxury motor vehicle manufacturers', 'Defunct motor vehicle manufacturers of Germany', 'Vehicle manufacturing companies disestablished in 1932']]\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt_dset.show([10, 20, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6d542-a884-4e8b-b561-76713f0e7bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548615d-90b6-4a55-b14c-d1cc8b02135a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
