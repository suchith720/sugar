{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1496512d-9c5f-4867-986c-fd24e7c6e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7782aa-4027-4fab-804c-433f4211b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0705a845-9af3-44da-a4b1-9a70146c1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import scipy.sparse as sp, re, xclib.data.data_utils as du, numpy as np, pandas as pd, os\n",
    "from IPython.display import display\n",
    "from torch.utils.data import Dataset\n",
    "from termcolor import colored, COLORS\n",
    "\n",
    "from sugar.core import *\n",
    "from xcai.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273f55a2-f1f9-484b-8168-1ac8f0ecddf5",
   "metadata": {},
   "source": [
    "## `UpdatedDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7063c54-cec2-4bd0-b095-32e5e54822a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "METADATA_CODE = {'category': 'cat', 'see_also': 'sal', 'hyper_link': 'hlk', 'videos': 'vid', 'images': 'img', \n",
    "                 'entity': 'ent', 'canonical': 'can', 'entity_canonical_category': 'ecc', 'entity_canonical': 'enc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a90ef9-70a0-4f03-970d-3cf670fcc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UpdatedDataset:\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data_info(data_dir, type):\n",
    "        ids, txt = load_raw_txt(f'{data_dir}/raw_data/{type}.raw.txt', encoding='latin-1')\n",
    "        return {'identifier':ids, 'input_text':txt}\n",
    "\n",
    "    @staticmethod\n",
    "    def load_lbl_info(data_dir, x_prefix, y_prefix):\n",
    "        ids, txt = load_raw_txt(f'{data_dir}/raw_data/label.{x_prefix}-{y_prefix}.raw.txt')\n",
    "        return {'identifier':ids, 'input_text':txt}\n",
    "\n",
    "    @staticmethod\n",
    "    def load_metadata_info(data_dir, metadata_type, x_prefix, y_prefix, z_prefix):\n",
    "        ids, txt = load_raw_txt(f'{data_dir}/raw_data/{metadata_type}.{x_prefix}-{y_prefix}-{z_prefix}.raw.txt')\n",
    "        return {'identifier':ids, 'input_text':txt}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_trn_tst_info(data_dir):\n",
    "        trn_info = UpdatedDataset.load_data_info(data_dir, 'train')\n",
    "        tst_info = UpdatedDataset.load_data_info(data_dir, 'test')\n",
    "        return trn_info, tst_info\n",
    "\n",
    "    @staticmethod\n",
    "    def get_labels(data_dir, x_prefix, y_prefix, old_dir=None):\n",
    "        if x_prefix == 'old' and y_prefix == 'old':\n",
    "            trn_mat = du.read_sparse_file(f'{old_dir}/trn_X_Y.txt')\n",
    "            tst_mat = du.read_sparse_file(f'{old_dir}/tst_X_Y.txt')\n",
    "        else:\n",
    "            trn_mat = sp.load_npz(f'{data_dir}/trn_X_Y_{x_prefix}-{y_prefix}.npz')\n",
    "            tst_mat = sp.load_npz(f'{data_dir}/tst_X_Y_{x_prefix}-{y_prefix}.npz')\n",
    "        \n",
    "        lbl_info = UpdatedDataset.load_lbl_info(data_dir, x_prefix=x_prefix, y_prefix=y_prefix)\n",
    "        \n",
    "        return trn_mat, tst_mat, lbl_info\n",
    "\n",
    "    @staticmethod\n",
    "    def get_metadata(data_dir, metadata_type, x_prefix, y_prefix, z_prefix, old_dir=None):\n",
    "        if x_prefix == 'old' and y_prefix == 'old' and z_prefix == 'old':\n",
    "            trn_mat = du.read_sparse_file(f'{old_dir}/{metadata_type}_trn_X_Y.txt')\n",
    "            tst_mat = du.read_sparse_file(f'{old_dir}/{metadata_type}_tst_X_Y.txt')\n",
    "            lbl_mat = du.read_sparse_file(f'{old_dir}/{metadata_type}_lbl_X_Y.txt')\n",
    "        else:\n",
    "            trn_mat = sp.load_npz(f'{data_dir}/{metadata_type}_trn_X_Y_{x_prefix}-{y_prefix}-{z_prefix}.npz')\n",
    "            tst_mat = sp.load_npz(f'{data_dir}/{metadata_type}_tst_X_Y_{x_prefix}-{y_prefix}-{z_prefix}.npz')\n",
    "            lbl_mat = sp.load_npz(f'{data_dir}/{metadata_type}_lbl_X_Y_{x_prefix}-{y_prefix}-{z_prefix}.npz')\n",
    "        \n",
    "        meta_info = UpdatedDataset.load_metadata_info(data_dir, metadata_type, x_prefix, y_prefix, z_prefix)\n",
    "        \n",
    "        return trn_mat, tst_mat, lbl_mat, meta_info\n",
    "\n",
    "    @staticmethod\n",
    "    def load_datasets(data_dir, save_dir, metadata_type, x_prefix, y_prefix, z_prefix):\n",
    "        trn_info, tst_info = UpdatedDataset.get_trn_tst_info(data_dir)\n",
    "        trn_mat, tst_mat, lbl_info = UpdatedDataset.get_labels(save_dir, x_prefix, y_prefix, data_dir)\n",
    "    \n",
    "        main_trn_dset = MainXCDataset(trn_info, trn_mat, lbl_info)\n",
    "        main_tst_dset = MainXCDataset(tst_info, tst_mat, lbl_info)\n",
    "    \n",
    "        trn_meta_mat, tst_meta_mat, lbl_meta_mat, meta_info = UpdatedDataset.get_metadata(save_dir, metadata_type, x_prefix, y_prefix, z_prefix, data_dir)\n",
    "    \n",
    "        trn_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], trn_meta_mat, lbl_meta_mat, meta_info)\n",
    "        tst_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], tst_meta_mat, lbl_meta_mat, meta_info)\n",
    "    \n",
    "        trn_dset = XCDataset(main_trn_dset, cat_meta=trn_meta_dset)\n",
    "        tst_dset = XCDataset(main_tst_dset, cat_meta=tst_meta_dset)\n",
    "    \n",
    "        return trn_dset, tst_dset\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98363dff-a26b-493c-a88d-9332e7c9aa93",
   "metadata": {},
   "source": [
    "## `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd33853-79ba-41f0-aee5-a033f38fd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Dataset:\n",
    "\n",
    "    @staticmethod\n",
    "    def load_data_info(data_dir, type):\n",
    "        ids, txt = load_raw_txt(f'{data_dir}/raw_data/{type}.raw.txt', encoding='latin-1')\n",
    "        return {'identifier':ids, 'input_text':txt}\n",
    "\n",
    "    @staticmethod\n",
    "    def load_lbl_info(data_dir):\n",
    "        ids, txt = load_raw_txt(f'{data_dir}/raw_data/label.raw.txt', encoding='latin-1')\n",
    "        return {'identifier':ids, 'input_text':txt}\n",
    "\n",
    "    @staticmethod\n",
    "    def load_metadata_info(data_dir, metadata_type, suffix=''):\n",
    "        if len(suffix): suffix = f'.{suffix}'\n",
    "        ids, txt = load_raw_txt(f'{data_dir}/raw_data/{metadata_type}{suffix}.raw.txt')\n",
    "        return {'identifier':ids, 'input_text':txt}\n",
    "\n",
    "    @staticmethod\n",
    "    def get_trn_tst_info(data_dir):\n",
    "        trn_info = Dataset.load_data_info(data_dir, 'train')\n",
    "        tst_info = Dataset.load_data_info(data_dir, 'test')\n",
    "        return trn_info, tst_info\n",
    "\n",
    "    @staticmethod\n",
    "    def get_labels(data_dir):\n",
    "        trn_mat = du.read_sparse_file(f'{data_dir}/trn_X_Y.txt') if os.path.exists(f'{data_dir}/trn_X_Y.txt') else sp.load_npz(f'{data_dir}/trn_X_Y.npz')\n",
    "        tst_mat = du.read_sparse_file(f'{data_dir}/tst_X_Y.txt') if os.path.exists(f'{data_dir}/tst_X_Y.txt') else sp.load_npz(f'{data_dir}/tst_X_Y.npz')\n",
    "            \n",
    "        lbl_info = Dataset.load_lbl_info(data_dir)\n",
    "        \n",
    "        return trn_mat, tst_mat, lbl_info\n",
    "\n",
    "    @staticmethod\n",
    "    def get_metadata(data_dir, metadata_type, suffix=''):\n",
    "        m_suffix = f'_{suffix}' if len(suffix) else suffix\n",
    "        trn_mat = sp.load_npz(f'{data_dir}/{metadata_type}_trn_X_Y{m_suffix}.npz')\n",
    "        tst_mat = sp.load_npz(f'{data_dir}/{metadata_type}_tst_X_Y{m_suffix}.npz')\n",
    "        lbl_mat = sp.load_npz(f'{data_dir}/{metadata_type}_lbl_X_Y{m_suffix}.npz')\n",
    "        \n",
    "        meta_info = Dataset.load_metadata_info(data_dir, metadata_type, suffix)\n",
    "        \n",
    "        return trn_mat, tst_mat, lbl_mat, meta_info\n",
    "\n",
    "    @staticmethod\n",
    "    def load_datasets(data_dir, metadata_type, suffix=''):\n",
    "        trn_info, tst_info = Dataset.get_trn_tst_info(data_dir)\n",
    "        trn_mat, tst_mat, lbl_info = Dataset.get_labels(data_dir)\n",
    "    \n",
    "        main_trn_dset = MainXCDataset(trn_info, trn_mat, lbl_info)\n",
    "        main_tst_dset = MainXCDataset(tst_info, tst_mat, lbl_info)\n",
    "    \n",
    "        trn_meta_mat, tst_meta_mat, lbl_meta_mat, meta_info = Dataset.get_metadata(data_dir, metadata_type, suffix)\n",
    "    \n",
    "        trn_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], trn_meta_mat, lbl_meta_mat, meta_info)\n",
    "        tst_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], tst_meta_mat, lbl_meta_mat, meta_info)\n",
    "    \n",
    "        trn_dset = XCDataset(main_trn_dset, cat_meta=trn_meta_dset)\n",
    "        tst_dset = XCDataset(main_tst_dset, cat_meta=tst_meta_dset)\n",
    "    \n",
    "        return trn_dset, tst_dset\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f204e61-12e8-45f6-a9de-6fbe4ef67982",
   "metadata": {},
   "source": [
    "## Compute statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1c875-103e-4264-8530-634dc1d06331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "CODE_METADATA = {'cat':'Category', 'sal':'Seealso', 'hlk':'hyperlink', 'vid':'Videos', 'img':'Images', \n",
    "                 'ent':'Entity', 'can':'Canonical', 'ecc':'Entity Canonical Category', 'enc':'Entity Canonical'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148017f-1745-41fa-9c42-98cb1073e50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def matrix_stats(mat):\n",
    "    n_dat = mat.shape[0]\n",
    "    n_lbl = mat.shape[1]\n",
    "\n",
    "    num_dat_lbl = mat.getnnz(axis=0)\n",
    "    num_lbl_dat = mat.getnnz(axis=1)\n",
    "\n",
    "    avg_dat_lbl = num_dat_lbl.mean()\n",
    "    avg_lbl_dat = num_lbl_dat.mean()\n",
    "\n",
    "    max_dat_lbl = num_dat_lbl.max()\n",
    "    max_lbl_dat = num_lbl_dat.max()\n",
    "\n",
    "    zro_dat_lbl = np.sum(num_dat_lbl == 0)\n",
    "    zro_lbl_dat = np.sum(num_lbl_dat == 0)\n",
    "\n",
    "    stats_dict = {\n",
    "        f'# Entries' : n_dat,\n",
    "        f'# Features': n_lbl,\n",
    "        f'Avg. Entries per feature' : avg_dat_lbl,\n",
    "        f'Avg. Feature per entry'   : avg_lbl_dat,\n",
    "        f'Max. Entries per feature' : max_dat_lbl,\n",
    "        f'Max. Feature per entry'   : max_lbl_dat,\n",
    "        f'# Features without entry' : zro_dat_lbl,\n",
    "        f'# Entries without feature': zro_lbl_dat,\n",
    "    }\n",
    "    return stats_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff3855-fe20-48e3-bf3b-c1a2d856e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def main_dset_stats(dset):\n",
    "    return matrix_stats(dset.data_lbl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3402404-adca-4e06-954b-0a4de32ef08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def meta_dset_stats(dset):\n",
    "    dat_stats = matrix_stats(dset.data_meta)\n",
    "    dat_stats['Dataset'] = 'Query'\n",
    "    \n",
    "    lbl_stats = matrix_stats(dset.lbl_meta)\n",
    "    lbl_stats['Dataset'] = 'Label'\n",
    "\n",
    "    return [dat_stats, lbl_stats]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798bf2cf-1712-48f3-91d4-22f073133ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def dset_stats(dset):\n",
    "    stats = []\n",
    "    \n",
    "    main_stats = main_dset_stats(dset.data)\n",
    "    main_stats['Dataset'] = 'Main'\n",
    "    stats.append(main_stats)\n",
    "\n",
    "    for o in dset.meta.values():\n",
    "        meta_stats = meta_dset_stats(o)\n",
    "        for s in meta_stats: s['Dataset'] = f'{s[\"Dataset\"]} {CODE_METADATA[o.prefix]} Metadata'\n",
    "        stats.extend(meta_stats)\n",
    "\n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a4fad-34b8-4dcd-a954-43153b104bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def trn_tst_stats(trn_dset, tst_dset):\n",
    "    trn_stats = dset_stats(trn_dset)\n",
    "    for o in trn_stats: o['Split'] = 'Train'\n",
    "\n",
    "    tst_stats = dset_stats(tst_dset)\n",
    "    for o in tst_stats: o['Split'] = 'Test'\n",
    "\n",
    "    stats = trn_stats + tst_stats\n",
    "    return stats\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61285a6-6a4e-483e-8596-8b60243f405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def print_stats(stats):\n",
    "    df = pd.DataFrame(stats).set_index(['Split', 'Dataset'])\n",
    "    with pd.option_context('display.precision', 2):\n",
    "        display(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31efabfa-62bf-460d-ab52-42b30929cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def print_dset_stats(trn_dset, tst_dset):\n",
    "    stats = trn_tst_stats(trn_dset, tst_dset)\n",
    "    print_stats(stats)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b08cbd-9b5f-40d8-aa2c-e1e47a32b854",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76def8-ba85-4d88-b092-36ac39cb237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TextDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dset, pattern='.*_text$'):\n",
    "        self.dset, self.pattern = dset, pattern\n",
    "        colors = list(COLORS.keys())\n",
    "        self.colors = [colors[i] for i in np.random.permutation(len(colors))]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        o = self.dset[idx]\n",
    "        return {k:v for k,v in o.items() if re.match(self.pattern, k)}\n",
    "\n",
    "    def show(self, idxs):\n",
    "        for idx in idxs:\n",
    "            for i,(k,v) in enumerate(self[idx].items()):\n",
    "                key = colored(k, self.colors[i], attrs=[\"reverse\", \"blink\"])\n",
    "                value = colored(f': {v}', self.colors[i])\n",
    "                print(key, value)\n",
    "            print()\n",
    "\n",
    "    def get_head_data(self, topk=10):\n",
    "        return np.argsort(self.dset.data.data_lbl.getnnz(axis=1))[:-topk:-1]\n",
    "\n",
    "    def get_tail_data(self, topk=10):\n",
    "        num = self.dset.data.data_lbl.getnnz(axis=1)\n",
    "        idx = np.argsort(num)\n",
    "        valid = (num > 0)[idx]\n",
    "        return idx[valid][:topk]\n",
    "        \n",
    "    def dump_txt(self, fname, idxs):\n",
    "        with open(fname, 'w') as file:\n",
    "            for idx in idxs:\n",
    "                for i,(k,v) in enumerate(self[idx].items()):\n",
    "                    file.write(f'{k}: {v}\\n')\n",
    "                file.write('\\n')\n",
    "            \n",
    "    def dump_csv(self, fname, idxs):\n",
    "        df = pd.DataFrame([self[idx] for idx in idxs])\n",
    "        df.to_csv(fname, index=False)\n",
    "\n",
    "    def dump(self, fname, idxs):\n",
    "        if fname.endswith('.txt'): \n",
    "            self.dump_txt(fname, idxs)\n",
    "        elif fname.endswith('.csv'): \n",
    "            self.dump_csv(fname, idxs)\n",
    "        else: \n",
    "            raise ValueError(f'Invalid file extension: {fname}')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb23a33-3366-463c-b5e7-eb5aa0ed1cc4",
   "metadata": {},
   "source": [
    "## Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5374de-8db2-4af1-973b-fef026580a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def show_updated_dataset(data_dir, save_dir, metadata_type, x_prefix, y_prefix, z_prefix, idxs, use_trn=True):\n",
    "    trn_dset, tst_dset = UpdatedDataset.load_datasets(data_dir, save_dir, metadata_type, x_prefix, y_prefix, z_prefix)\n",
    "    print_dset_stats(trn_dset, tst_dset)\n",
    "    \n",
    "    txt_dset = TextDataset(trn_dset if use_trn else tst_dset)\n",
    "    txt_dset.show(idxs)\n",
    "    \n",
    "    return trn_dset, tst_dset\n",
    "\n",
    "def show_dataset(data_dir, metadata_type, idxs, suffix='', use_trn=True):\n",
    "    trn_dset, tst_dset = Dataset.load_datasets(data_dir, metadata_type, suffix=suffix)\n",
    "    print_dset_stats(trn_dset, tst_dset)\n",
    "    \n",
    "    txt_dset = TextDataset(trn_dset if use_trn else tst_dset)\n",
    "    txt_dset.show(idxs)\n",
    "    \n",
    "    return trn_dset, tst_dset\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087e30b-2b43-4ab7-b951-80a18a5b3049",
   "metadata": {},
   "source": [
    "## `__main__`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcdf79f-5c91-48fc-9600-ada3745a09d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_dir', type=str, required=True)\n",
    "    parser.add_argument('--save_dir', type=str, required=True)\n",
    "    parser.add_argument('--metadata_key', type=str, required=None)\n",
    "    parser.add_argument('--x_prefix', type=str, required=True)\n",
    "    parser.add_argument('--y_prefix', type=str, required=True)\n",
    "    parser.add_argument('--z_prefix', type=str, required=True)\n",
    "    return parser.parse_args()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f1e4f-fa00-40df-a777-8f8c6d89c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    trn_dset, tst_dset = UpdatedDataset.load_datasets(args.data_dir, args.save_dir, args.metadata_type, \n",
    "                                                      args.x_prefix, args.y_prefix, args.z_prefix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa8b0e-24ef-44bc-94fc-c371eb418165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef98589-8392-4abc-9479-26aaeba1c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/scai/phd/aiz218323/scratch/datasets/benchmarks/(mapped)LF-WikiSeeAlsoTitles-320K/'\n",
    "save_dir = '/home/scai/phd/aiz218323/scratch/datasets/wikipedia/20250123/LF-WikiSeeAlsoTitles-320K/'\n",
    "\n",
    "metadata_type = 'category'\n",
    "x_prefix, y_prefix, z_prefix = 'old', 'new', 'new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2a73e-89e4-4c5d-86c7-53cceb331a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dset, tst_dset = UpdatedDataset.load_datasets(data_dir, save_dir, metadata_type, x_prefix, y_prefix, z_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b5413-c8b4-41ca-9f73-3cb14c93dbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th># Entries</th>\n",
       "      <th># Features</th>\n",
       "      <th>Avg. Entries per feature</th>\n",
       "      <th>Avg. Feature per entry</th>\n",
       "      <th>Max. Entries per feature</th>\n",
       "      <th>Max. Feature per entry</th>\n",
       "      <th># Features without entry</th>\n",
       "      <th># Entries without feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split</th>\n",
       "      <th>Dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Train</th>\n",
       "      <th>Main</th>\n",
       "      <td>693082</td>\n",
       "      <td>573503</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2358</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>95940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query Category Metadata</th>\n",
       "      <td>693082</td>\n",
       "      <td>872994</td>\n",
       "      <td>4.16</td>\n",
       "      <td>5.24</td>\n",
       "      <td>36700</td>\n",
       "      <td>245</td>\n",
       "      <td>136111</td>\n",
       "      <td>60302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Category Metadata</th>\n",
       "      <td>573503</td>\n",
       "      <td>872994</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.98</td>\n",
       "      <td>7824</td>\n",
       "      <td>247</td>\n",
       "      <td>287010</td>\n",
       "      <td>147334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Test</th>\n",
       "      <th>Main</th>\n",
       "      <td>177515</td>\n",
       "      <td>573503</td>\n",
       "      <td>0.89</td>\n",
       "      <td>2.88</td>\n",
       "      <td>244</td>\n",
       "      <td>121</td>\n",
       "      <td>296707</td>\n",
       "      <td>28176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Query Category Metadata</th>\n",
       "      <td>177515</td>\n",
       "      <td>872994</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.09</td>\n",
       "      <td>6639</td>\n",
       "      <td>247</td>\n",
       "      <td>526146</td>\n",
       "      <td>13005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label Category Metadata</th>\n",
       "      <td>573503</td>\n",
       "      <td>872994</td>\n",
       "      <td>2.62</td>\n",
       "      <td>3.98</td>\n",
       "      <td>7824</td>\n",
       "      <td>247</td>\n",
       "      <td>287010</td>\n",
       "      <td>147334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               # Entries  # Features  \\\n",
       "Split Dataset                                          \n",
       "Train Main                        693082      573503   \n",
       "      Query Category Metadata     693082      872994   \n",
       "      Label Category Metadata     573503      872994   \n",
       "Test  Main                        177515      573503   \n",
       "      Query Category Metadata     177515      872994   \n",
       "      Label Category Metadata     573503      872994   \n",
       "\n",
       "                               Avg. Entries per feature  \\\n",
       "Split Dataset                                             \n",
       "Train Main                                         2.75   \n",
       "      Query Category Metadata                      4.16   \n",
       "      Label Category Metadata                      2.62   \n",
       "Test  Main                                         0.89   \n",
       "      Query Category Metadata                      1.03   \n",
       "      Label Category Metadata                      2.62   \n",
       "\n",
       "                               Avg. Feature per entry  \\\n",
       "Split Dataset                                           \n",
       "Train Main                                       2.28   \n",
       "      Query Category Metadata                    5.24   \n",
       "      Label Category Metadata                    3.98   \n",
       "Test  Main                                       2.88   \n",
       "      Query Category Metadata                    5.09   \n",
       "      Label Category Metadata                    3.98   \n",
       "\n",
       "                               Max. Entries per feature  \\\n",
       "Split Dataset                                             \n",
       "Train Main                                         2358   \n",
       "      Query Category Metadata                     36700   \n",
       "      Label Category Metadata                      7824   \n",
       "Test  Main                                          244   \n",
       "      Query Category Metadata                      6639   \n",
       "      Label Category Metadata                      7824   \n",
       "\n",
       "                               Max. Feature per entry  \\\n",
       "Split Dataset                                           \n",
       "Train Main                                        136   \n",
       "      Query Category Metadata                     245   \n",
       "      Label Category Metadata                     247   \n",
       "Test  Main                                        121   \n",
       "      Query Category Metadata                     247   \n",
       "      Label Category Metadata                     247   \n",
       "\n",
       "                               # Features without entry  \\\n",
       "Split Dataset                                             \n",
       "Train Main                                            0   \n",
       "      Query Category Metadata                    136111   \n",
       "      Label Category Metadata                    287010   \n",
       "Test  Main                                       296707   \n",
       "      Query Category Metadata                    526146   \n",
       "      Label Category Metadata                    287010   \n",
       "\n",
       "                               # Entries without feature  \n",
       "Split Dataset                                             \n",
       "Train Main                                         95940  \n",
       "      Query Category Metadata                      60302  \n",
       "      Label Category Metadata                     147334  \n",
       "Test  Main                                         28176  \n",
       "      Query Category Metadata                      13005  \n",
       "      Label Category Metadata                     147334  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_dset_stats(trn_dset, tst_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23752dcd-98a8-443f-9c9d-554317906cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31211865-0322-4406-a4a9-ce6b55ac01a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_dset = TextDataset(trn_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db5ce34-645b-461b-aec9-1db15c3596b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_dset.dump(f'{save_dir}/examples/random_{metadata_type}_{x_prefix}-{y_prefix}-{z_prefix}.txt', [10, 20, 30])\n",
    "txt_dset.dump(f'{save_dir}/examples/random_{metadata_type}_{x_prefix}-{y_prefix}-{z_prefix}.csv', [10, 20, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc2f72-b8d3-4592-8a08-354066aa8a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[7m\u001b[35mdata_input_text\u001b[0m \u001b[35m: Austroasiatic languages\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[34mlbl2data_input_text\u001b[0m \u001b[34m: []\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[93mcat2data_input_text\u001b[0m \u001b[93m: ['Austroasiatic languages', 'Language families']\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[31mcat2lbl2data_input_text\u001b[0m \u001b[31m: []\u001b[0m\n",
      "\n",
      "\u001b[5m\u001b[7m\u001b[35mdata_input_text\u001b[0m \u001b[35m: Albania\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[34mlbl2data_input_text\u001b[0m \u001b[34m: ['Outline of Albania', 'Bibliography of Albania']\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[93mcat2data_input_text\u001b[0m \u001b[93m: ['Countries in Europe', 'Albania', 'Balkan countries', 'Member states of the Organisation internationale de la Francophonie', 'Countries and territories where Albanian is an official language', 'Member states of the United Nations', 'Republics', 'Member states of the Council of Europe', 'Member states of NATO', 'Member states of the Union for the Mediterranean', 'Member states of the Organisation of Islamic Cooperation', 'States and territories established in 1912']\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[31mcat2lbl2data_input_text\u001b[0m \u001b[31m: [['Albania', 'Outlines of countries', 'Outlines', 'Albania-related lists'], ['Albanian studies', 'Bibliographies of countries or regions']]\u001b[0m\n",
      "\n",
      "\u001b[5m\u001b[7m\u001b[35mdata_input_text\u001b[0m \u001b[35m: Altaic languages\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[34mlbl2data_input_text\u001b[0m \u001b[34m: ['Uralo-Siberian languages', 'Comparison of Japanese and Korean', 'Nostratic languages', 'Classification of the Japonic languages', 'Turco-Mongol', 'Xiongnu', 'Pan-Turanism']\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[93mcat2data_input_text\u001b[0m \u001b[93m: ['Sprachbund', 'Agglutinative languages', 'Proposed language families', 'Altaic languages', 'Central Asia']\u001b[0m\n",
      "\u001b[5m\u001b[7m\u001b[31mcat2lbl2data_input_text\u001b[0m \u001b[31m: [['Eskaleut languages', 'Uralic languages', 'Proposed language families', 'Paleo-Siberian languages', 'History of Northeast Asia'], ['Japanese language', 'Language comparison', 'Korean language'], ['Moscow School of Comparative Linguistics', 'Fringe theories', '1903 in science', 'Linguistic theories and hypotheses', 'Nostratic languages', 'Proposed language families'], ['Japanese language', 'Language classification', 'Japonic languages'], [], ['Former confederations', 'Xiongnu', '460 disestablishments', 'States and territories established in the 3rd century BC', 'Former countries in Chinese history', 'Nomadic confederacies', 'States and territories disestablished in the 1st century', 'Ancient peoples of China', 'Nomadic empires', 'Han dynasty'], []]\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "txt_dset.show([10, 20, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6d542-a884-4e8b-b561-76713f0e7bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548615d-90b6-4a55-b14c-d1cc8b02135a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
