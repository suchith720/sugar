{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9081054-bc68-44cf-94db-ccb23424d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 26_beir-substring-metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d8b190b-5815-464e-ba3c-7a6012257127",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7efd5bf2-061e-4827-802d-13b1d3f7751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, json, pandas as pd, ast, scipy.sparse as sp, json_repair, numpy as np, re\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Optional, Dict, List\n",
    "from xcai.misc import BEIR_DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd49b4c-2ca4-47cb-ae27-0cbd1ccfbc51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `Helper functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6b94d33f-0590-49e2-9748-30f9713050f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_gpt_outputs(fname:str):\n",
    "    outputs = dict()\n",
    "    with open(fname) as file:\n",
    "        for line in file:\n",
    "            content = json.loads(line)\n",
    "            outputs[content[\"doc_id\"]] = content[\"output\"]\n",
    "    return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b3d6b584-fd90-44b5-b98b-838f92a703a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_label_metadata(outputs:Dict, labels:pd.DataFrame):\n",
    "    return [outputs.get(i, {}) for i in labels[\"identifier\"]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a4e7daa3-5659-4045-a8be-a9693ff3049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_label_substring_metadata(outputs:Dict):\n",
    "    # substring metadata\n",
    "    \n",
    "    phrases = dict()\n",
    "    vocab, data, indices, indptr = dict(), [], [], [0]\n",
    "    for output in tqdm(outputs):\n",
    "        for o in output.get(\"substring\", []):\n",
    "            if len(o):\n",
    "                idx = vocab.setdefault(o[\"original_substring\"], len(vocab))\n",
    "                data.append(1)\n",
    "                indices.append(idx)\n",
    "                assert np.all([type(i) == str for i in o[\"derived_phrases\"]]), '\"derived_phrases\" should be list of string'\n",
    "                phrases.setdefault(idx, []).extend(o[\"derived_phrases\"])\n",
    "        indptr.append(len(data))\n",
    "        \n",
    "    lbl_sub = sp.csr_matrix((data, indices, indptr))\n",
    "    sub_info = pd.DataFrame([(v,k) for k,v in vocab.items()], columns=[\"identifier\", \"text\"])\n",
    "\n",
    "    # derived phrases metadata\n",
    "    \n",
    "    vocab, data, indices, indptr = dict(), [], [], [0]\n",
    "    for i in range(sub_info.shape[0]):\n",
    "        for p in phrases[i]:\n",
    "            idx = vocab.setdefault(p, len(vocab))\n",
    "            data.append(1)\n",
    "            indices.append(idx)\n",
    "        indptr.append(len(data))\n",
    "\n",
    "    sub_phs = sp.csr_matrix((data, indices, indptr))\n",
    "    phs_info = pd.DataFrame([(v,k) for k,v in vocab.items()], columns=[\"identifier\", \"text\"])\n",
    "    \n",
    "    return lbl_sub, sub_info, sub_phs, phs_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d1dcc5c9-545f-4b05-8c0d-f868ccfc07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_query_substring_metadata(outputs:Dict, sub_info:pd.DataFrame):\n",
    "    sub_vocab = {v:i for i,(k,v) in sub_info.iterrows()}\n",
    "    \n",
    "    # query-substring\n",
    "    \n",
    "    query, derived_queries = [], []\n",
    "    data, indices, indptr = [], [], [0]\n",
    "    for output in tqdm(outputs):\n",
    "        for i,o in enumerate(output.get(\"queries\", [])):\n",
    "            query.append(o[\"primary_query\"])\n",
    "            idxs = [sub_vocab.setdefault(a, len(sub_vocab)) for a in o[\"answer\"]]\n",
    "            data.extend([1] * len(idxs))\n",
    "            indices.extend(idxs)\n",
    "            indptr.append(len(data))\n",
    "            derived_queries.append(o[\"derived_queries\"])\n",
    "            \n",
    "    data_sub = sp.csr_matrix((data, indices, indptr))\n",
    "    data_info = pd.DataFrame([(k,v) for k,v in enumerate(query)], columns=[\"identifier\", \"text\"])\n",
    "    sub_info = pd.DataFrame([(v,k) for k,v in sub_vocab.items()], columns=[\"identifier\", \"text\"])\n",
    "\n",
    "    # query-derived_queries\n",
    "    \n",
    "    vocab, data, indices, indptr = dict(), [], [], [0]\n",
    "    for queries in derived_queries:\n",
    "        for q in queries:\n",
    "            idx = vocab.setdefault(q, len(vocab))\n",
    "            data.append(1)\n",
    "            indices.append(idx)\n",
    "        indptr.append(len(data))\n",
    "\n",
    "    data_der = sp.csr_matrix((data, indices, indptr))\n",
    "    der_info = pd.DataFrame([(v,k) for k,v in vocab.items()], columns=[\"identifier\", \"text\"])\n",
    "\n",
    "    return data_sub, data_info, sub_info, data_der, der_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7a2a16fe-bf4c-4635-a743-f148b9c34e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def is_valid_output(v:Dict):        \n",
    "    if type(v) == dict:\n",
    "        if \"substring\" in v:\n",
    "            for o in v[\"substring\"]:\n",
    "                if len(o):\n",
    "                    if not (\"original_substring\" in o and isinstance(o[\"original_substring\"], str)):\n",
    "                        return False\n",
    "                        \n",
    "                    if \"derived_phrases\" in o and isinstance(o[\"derived_phrases\"], list):\n",
    "                        if not np.all([isinstance(i, str) for i in o[\"derived_phrases\"]]):\n",
    "                            return False\n",
    "                    else:\n",
    "                        return False\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "        if \"queries\" in v:\n",
    "            for o in v[\"queries\"]:\n",
    "                if not (\"primary_query\" in o and isinstance(o[\"primary_query\"], str)):\n",
    "                    return False\n",
    "    \n",
    "                if \"derived_queries\" in o and isinstance(o[\"derived_queries\"], list):\n",
    "                    if not np.all([isinstance(i, str) for i in o[\"derived_queries\"]]):\n",
    "                        return False\n",
    "                else:\n",
    "                    return False\n",
    "    \n",
    "                if \"answer\" in o and isinstance(o[\"answer\"], list):\n",
    "                    if not np.all([isinstance(i, str) for i in o[\"answer\"]]):\n",
    "                        return False\n",
    "                else:\n",
    "                    return False\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "69630f27-0180-434c-92e5-cea52459103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_string_to_objects(outputs:Dict):\n",
    "    \n",
    "    def get_line_number(pat:str, e:str):\n",
    "        m = re.match(pat, str(e))\n",
    "        return int(m.group(1)) - 1\n",
    "        \n",
    "    out, n_invalid = dict(), 0\n",
    "    for k,v in tqdm(outputs.items()):\n",
    "        error_flag, n_tries = True, 0\n",
    "\n",
    "        if len(v) == 0: continue\n",
    "        \n",
    "        while error_flag:\n",
    "            o = json_repair.loads(v)\n",
    "\n",
    "            if \"substrings\" in o:\n",
    "                o[\"substring\"] = o.pop(\"substrings\")\n",
    "            \n",
    "            if not is_valid_output(o):\n",
    "                try:\n",
    "                    out[k] = ast.literal_eval(v)\n",
    "                    error_flag = False\n",
    "                except Exception as e:\n",
    "                    patterns = [\n",
    "                        r\"closing parenthesis '\\)' does not match opening parenthesis '\\[.*line (\\d+)\",\n",
    "                        r\"unterminated string literal \\(detected at line \\d+\\).*line (\\d+)\\)\",\n",
    "                        r\"invalid character '’' \\(U\\+2019\\) .*line (\\d+)\\)\",\n",
    "                        r\"invalid syntax .*line (\\d+)\\)\",\n",
    "                        r\"closing parenthesis '\\]' does not match opening parenthesis '\\{' on line \\d+ .*line (\\d+)\\)\",\n",
    "                    ]\n",
    "                    \n",
    "                    def func_1(line:str):\n",
    "                        if line[-1] == \"]\":\n",
    "                            line = line.replace(\")\", \"\")\n",
    "                        else:\n",
    "                            line = line.replace(\")\", \"]\")\n",
    "                        return line\n",
    "\n",
    "                    def func_2(line:str):\n",
    "                        line = line.replace('”', '\"').replace('“', '\"')\n",
    "                        if line[-1] == \"]\" and line[-2].strip() != '\"':\n",
    "                            line = line[:-1] + '\"]'\n",
    "                        if line[-2:] == \"*/\":\n",
    "                            line = line[:-2] + '\"]'\n",
    "                        return line\n",
    "                        \n",
    "                    def func_3(line:str):\n",
    "                        return line.replace(\"’\", \"'\")\n",
    "\n",
    "                    def func_4(line:str):\n",
    "                        if line[-1] == \";\": line = line[:-1]\n",
    "                        return line\n",
    "\n",
    "                    def func_5(line:str):\n",
    "                        return line.replace(\"]\", \"} ]\")\n",
    "\n",
    "                    functions = [func_1, func_2, func_3, func_4, func_5]\n",
    "\n",
    "                    n_tries += 1\n",
    "                    if n_tries > 10:\n",
    "                        n_invalid += 1\n",
    "                        break\n",
    "                        \n",
    "                    for pat, func in zip(patterns, functions):\n",
    "                        if re.match(pat, str(e)):\n",
    "                            idx = get_line_number(pat, e)\n",
    "                            lines = v.split(\"\\n\") \n",
    "                            lines[idx] = func(lines[idx])\n",
    "                            v = \"\\n\".join(lines)\n",
    "                            break\n",
    "                    else:\n",
    "                        raise ValueError(f\"Keyword error: {k}\")\n",
    "                        \n",
    "            else:\n",
    "                out[k] = o\n",
    "                error_flag = False\n",
    "\n",
    "    if n_invalid > 0: print(f\"Invalid outputs: {n_invalid/len(outputs):.4f}\")\n",
    "        \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "82d75225-acaa-415c-bcb7-6e4642d1e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_data(save_dir:str, dtype:str, data_sub:sp.csr_matrix, data_info:pd.DataFrame, sub_info:pd.DataFrame, \n",
    "              lbl_sub:sp.csr_matrix, sub_phs:sp.csr_matrix, phs_info:pd.DataFrame, data_der:sp.csr_matrix, \n",
    "              der_info:pd.DataFrame):\n",
    "    os.makedirs(f\"{save_dir}/raw_data/\", exist_ok=True)\n",
    "    short_hand = {\"simple-query\": \"sq\", \"multihop-query\": \"mq\"}\n",
    "\n",
    "    assert dtype in short_hand, f\"Invalid data-type: {dtype}.\"\n",
    "\n",
    "    data_info.to_csv(f\"{save_dir}/raw_data/{dtype}.raw.csv\", index=False)\n",
    "    sub_info.to_csv(f\"{save_dir}/raw_data/{short_hand[dtype]}-substring.raw.csv\", index=False)\n",
    "    \n",
    "    der_info.to_csv(f\"{save_dir}/raw_data/{short_hand[dtype]}-derived-queries.raw.csv\", index=False)\n",
    "\n",
    "    sp.save_npz(f\"{save_dir}/{dtype}_{short_hand[dtype]}-substring.npz\", data_sub)\n",
    "    sp.save_npz(f\"{save_dir}/{dtype}_{short_hand[dtype]}-derived-queries.npz\", data_der)\n",
    "\n",
    "    lbl_sub.resize((lbl_sub.shape[0], sub_info.shape[0]))\n",
    "    sub_phs.resize((sub_info.shape[0], sub_phs.shape[1]))\n",
    "\n",
    "    sp.save_npz(f\"{save_dir}/lbl_{short_hand[dtype]}-substring.npz\", lbl_sub)\n",
    "    sp.save_npz(f\"{save_dir}/{short_hand[dtype]}-substring_{short_hand[dtype]}-derived-phrases.npz\", sub_phs)\n",
    "\n",
    "    phs_info.to_csv(f\"{save_dir}/raw_data/{short_hand[dtype]}-substring_{short_hand[dtype]}-derived-phrases.raw.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007c5e25-b20f-4442-ac5d-f2779c26df7e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## `Extract substring`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2b14bbe4-498b-4dd1-a8c0-3def46f0edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def proc_dataset(dataset:str, lbl_dir:str, data_dir:str, save_dir:Optional[str]=None):\n",
    "    lbl_file = f\"{lbl_dir}/{dataset}/XC/raw_data/label.raw.csv\"\n",
    "    labels = pd.read_csv(lbl_file)\n",
    "\n",
    "    for dtype in [\"simple\", \"multihop\"]:\n",
    "        outputs = load_gpt_outputs(f\"{data_dir}/{dataset}_{dtype}_label.jsonl\")\n",
    "        \n",
    "        outputs = convert_string_to_objects(outputs)\n",
    "        outputs = get_label_metadata(outputs, labels)\n",
    "\n",
    "        lbl_sub, sub_info, sub_phs, phs_info = get_label_substring_metadata(outputs)\n",
    "        data_sub, data_info, sub_info, data_der, der_info = get_query_substring_metadata(outputs, sub_info)\n",
    "\n",
    "        save_dir = f\"{lbl_dir}/{dataset}/XC/document_substring/\" if save_dir is None else save_dir\n",
    "        save_data(save_dir, f\"{dtype}-query\", data_sub, data_info, sub_info, lbl_sub, sub_phs, phs_info, \n",
    "                  data_der, der_info)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8e63c3-bd91-424f-b4dd-ac2147bbd06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def main(lbl_dir:str, data_dir:str, save_dir:Optional[str]=None):\n",
    "    for dataset in tqdm(BEIR_DATASETS):\n",
    "        proc_dataset(dataset, lbl_dir, data_dir, save_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17b032-bdfc-4627-b101-9d0d7370da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == \"__main__\":\n",
    "    lbl_dir = \"/Users/suchith720/Projects/data/beir/\"\n",
    "    data_dir = \"/Users/suchith720/Downloads/\"\n",
    "    main(lbl_dir, data_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afaa2f02-8eb0-41fd-b468-0d6118e151fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"/Users/suchith720/Projects/data/beir/arguana/XC/document_substring/raw_data/mq-derived-queries.raw.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b34f8e5-b51d-4a1d-841e-1fa0de747d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09d35c92-53f1-4c07-b27f-fc063fc74c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>According to British farmer Simon Farrell, wha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What figure did Simon Farrell state as the UN'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Simon Farrell challenges UN data; what percent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>In disputing UN's livestock carbon estimate, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>What global carbon emissions percentage is att...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identifier                                               text\n",
       "0           0  According to British farmer Simon Farrell, wha...\n",
       "1           1  What figure did Simon Farrell state as the UN'...\n",
       "2           2  Simon Farrell challenges UN data; what percent...\n",
       "3           3  In disputing UN's livestock carbon estimate, w...\n",
       "4           4  What global carbon emissions percentage is att..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5adc8-814b-4972-b572-7fed247b64a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
