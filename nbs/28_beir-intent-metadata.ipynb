{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9081054-bc68-44cf-94db-ccb23424d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp 28_beir-intent-metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d8b190b-5815-464e-ba3c-7a6012257127",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7efd5bf2-061e-4827-802d-13b1d3f7751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os, json, pandas as pd, ast, scipy.sparse as sp, json_repair, numpy as np, re\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "\n",
    "from xcai.misc import BEIR_DATASETS\n",
    "from sugar.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd49b4c-2ca4-47cb-ae27-0cbd1ccfbc51",
   "metadata": {},
   "source": [
    "## `Helper functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "362dad8b-a0bf-482f-b907-ce9c3b0a5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_raw(fname:str, ids:List, txt:List):\n",
    "    df = pd.DataFrame({\"identifier\": ids, \"text\": txt})\n",
    "    df.to_csv(fname, index=False)\n",
    "\n",
    "def load_raw(fname:str):\n",
    "    df = pd.read_csv(fname, keep_default_na=False, na_filter=False)\n",
    "    return df[\"identifier\"].tolist(), df[\"text\"].tolist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02df312f-f935-4bb5-bdbb-dc7048347599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06992022-ca92-4236-a9b0-74a3b08b3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def combine_df(dirname:str, dtype:str):\n",
    "    assert dtype in [\"single\", \"multihop\"]\n",
    "    return pd.concat([pd.read_table(f\"{dirname}/{fname}\") for fname in os.listdir(dirname) if dtype in fname])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "909600fd-3dd6-410b-ae1b-bf13b9b90411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_string_to_object(output:Dict):\n",
    "    try:\n",
    "        if output[:9] == \"```python\": output = output[9:]\n",
    "        if output[-3:] == \"```\": output = output[:-3]\n",
    "        return ast.literal_eval(output)\n",
    "    except:\n",
    "        return json_repair.loads(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706a989a-7544-408c-9368-cf474856fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def convert_df_into_label_dict(df:pd.DataFrame):\n",
    "    outputs = {}\n",
    "    for i,row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        lbl_id, lbl_txt = str(row[\"id\"]), row[\"document\"]\n",
    "        try:\n",
    "            substring = convert_string_to_object(row[\"raw_model_response\"])\n",
    "        except:\n",
    "            raise ValueError(f\"Invalid model response at row #{i}\")\n",
    "            \n",
    "        assert lbl_id not in outputs\n",
    "        \n",
    "        outputs[lbl_id] = {\n",
    "            \"label_id\": lbl_id,\n",
    "            \"label_text\": lbl_txt,\n",
    "            \"substring\": substring,\n",
    "        }\n",
    "    return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67c966-c46c-4559-9326-312de2bb762c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fe0b3a48-3bd1-47e6-83ff-8123d33dba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_metadata_matrix_from_label_dict(outputs:Dict, lbl_ids:List, seed:Optional[int]=100):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "\n",
    "    intent_info = {\n",
    "        \"phrases\": dict(), \n",
    "        \"intents\": dict(), \n",
    "        \"substr\": dict(),\n",
    "    }\n",
    "    \n",
    "    lbl_info = {\n",
    "        \"query\": dict(), \n",
    "        \"queries\": dict(),\n",
    "    }\n",
    "    \n",
    "    substr2intent = dict()\n",
    "\n",
    "    lbl_mat = {\n",
    "        \"vocab\": dict(),\n",
    "        \"data\": [],\n",
    "        \"indices\": [],\n",
    "        \"indptr\": [0],\n",
    "    }\n",
    "\n",
    "    qry_mat = {\n",
    "        \"text\": [],\n",
    "        \"data\": [],\n",
    "        \"indices\": [],\n",
    "        \"indptr\": [0],\n",
    "    }\n",
    "\n",
    "    def get_original_substring_key(gen):\n",
    "        for k in gen:\n",
    "            if \"original\" in k and \"substring\" in k:\n",
    "                return k\n",
    "        else:\n",
    "            raise ValueError(f\"`original_substring` absent.\")\n",
    "            \n",
    "    for l in tqdm(lbl_ids):\n",
    "        o = outputs.get(l, {})\n",
    "        generations = o.get(\"substring\", {})\n",
    "        \n",
    "        for gen in generations.get(\"substring\", []):\n",
    "            intent = str(np.random.choice(gen[\"intent_phrases\"]))\n",
    "            substr2intent[gen[get_original_substring_key(gen)]] = intent\n",
    "            \n",
    "            idx = lbl_mat[\"vocab\"].setdefault(intent, len(lbl_mat[\"vocab\"]))\n",
    "            lbl_mat[\"indices\"].append(idx)\n",
    "            lbl_mat[\"data\"].append(1.0)\n",
    "\n",
    "            if idx == 2955:\n",
    "                print(idx)\n",
    "                import pdb; pdb.set_trace()\n",
    "                \n",
    "            intent_info[\"phrases\"].setdefault(idx, []).extend(gen[\"derived_phrases\"])\n",
    "            intent_info[\"intents\"].setdefault(idx, []).extend(gen[\"intent_phrases\"])\n",
    "            intent_info[\"substr\"].setdefault(idx, []).append(gen[get_original_substring_key(gen)])\n",
    "            \n",
    "        lbl_mat[\"indptr\"].append(len(lbl_mat[\"indices\"]))\n",
    "\n",
    "        for gen in generations.get(\"queries\", []):\n",
    "            text = str(np.random.choice(gen[\"derived_queries\"]))\n",
    "            \n",
    "            qry_mat[\"text\"].append(text)\n",
    "\n",
    "            if \"intent_phrases\" in gen:\n",
    "                indices = [lbl_mat[\"vocab\"].setdefault(substr2intent.get(o, str(np.random.choice(gen[\"intent_phrases\"]))), len(lbl_mat[\"vocab\"])) for o in gen[\"answer\"]]\n",
    "            else:\n",
    "                try:\n",
    "                    indices = [lbl_mat[\"vocab\"][substr2intent[o]] for o in gen[\"answer\"]]\n",
    "                except:\n",
    "                    indices = [lbl_mat[\"vocab\"].setdefault(substr2intent.get(o, o), len(lbl_mat[\"vocab\"])) for o in gen[\"answer\"]]\n",
    "            \n",
    "            qry_mat[\"data\"].extend([1.0] * len(indices))\n",
    "            qry_mat[\"indices\"].extend(indices)\n",
    "            qry_mat[\"indptr\"].append(len(qry_mat[\"indices\"]))\n",
    "                \n",
    "            lbl_info[\"query\"].setdefault(l, []).append(text)\n",
    "            lbl_info[\"queries\"].setdefault(l, []).extend(gen[\"derived_queries\"] + [gen[\"primary_query\"]])\n",
    "\n",
    "    shape = (len(lbl_mat[\"indptr\"]) - 1, len(lbl_mat[\"vocab\"]))\n",
    "    lbl_intent = sp.csr_matrix((lbl_mat[\"data\"], lbl_mat[\"indices\"], lbl_mat[\"indptr\"]), shape=shape, dtype=np.float32)\n",
    "    \n",
    "    shape = (len(qry_mat[\"text\"]), len(lbl_mat[\"vocab\"]))\n",
    "    qry_intent = sp.csr_matrix((qry_mat[\"data\"], qry_mat[\"indices\"], qry_mat[\"indptr\"]), shape=shape, dtype=np.float32)\n",
    "\n",
    "    return lbl_mat[\"vocab\"], lbl_intent, qry_mat[\"text\"], qry_intent, intent_info, lbl_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c4e10222-18ae-4f5f-a581-b311c114c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_matrix_from_dict(metadata:Dict, ids:List):\n",
    "    vocab, data, indices, indptr = dict(), [], [], [0]\n",
    "    for i in tqdm(ids):\n",
    "        indices.extend([vocab.setdefault(o, len(vocab)) for o in metadata.get(i, [])])\n",
    "        data.extend([1.0] * len(metadata.get(i, [])))\n",
    "        indptr.append(len(indices))\n",
    "    return sp.csr_matrix((data, indices, indptr), dtype=np.float32), vocab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44d6401-f5a1-480a-b37e-921bf2369cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0aa25ebf-5ec5-4917-9177-bb8a6e03eee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def extract_metadata(dirname:str, dtype:str, lbl_ids:List):\n",
    "    df = combine_df(dirname, dtype)\n",
    "    \n",
    "    outputs = convert_df_into_label_dict(df)\n",
    "\n",
    "    o = get_metadata_matrix_from_label_dict(outputs, lbl_ids)\n",
    "    intent_vocab, lbl_intent, qry_txt, qry_intent, intent_info, lbl_info = o\n",
    "    qry_ids = list(range(len(qry_txt)))\n",
    "\n",
    "    intent_txt = sorted(intent_vocab, key=lambda x:intent_vocab[x])\n",
    "    intent_ids = list(range(len(intent_txt)))\n",
    "    \n",
    "    assert len(intent_ids) == lbl_intent.shape[1], (\n",
    "        f\"Intent count mismatch: expected {lbl_intent.shape[1]}, got {len(intent_ids)}\"\n",
    "    )\n",
    "    assert len(intent_ids) == qry_intent.shape[1], (\n",
    "        f\"Intent count mismatch: expected {qry_intent.shape[1]}, got {len(intent_ids)}\"\n",
    "    )\n",
    "\n",
    "    intent_phrase, phrase_vocab = get_matrix_from_dict(intent_info[\"phrases\"], intent_ids)\n",
    "    intent_intents, intents_vocab = get_matrix_from_dict(intent_info[\"intents\"], intent_ids)\n",
    "    intent_substr, substr_vocab = get_matrix_from_dict(intent_info[\"substr\"], intent_ids)\n",
    "\n",
    "    lbl_query, query_vocab = get_matrix_from_dict(lbl_info[\"query\"], lbl_ids)\n",
    "    lbl_queries, queries_vocab = get_matrix_from_dict(lbl_info[\"queries\"], lbl_ids)\n",
    "\n",
    "    intent_info = (intent_phrase, phrase_vocab), (intent_intents, intents_vocab), (intent_substr, substr_vocab)\n",
    "    lbl_info = (lbl_query, query_vocab), (lbl_queries, queries_vocab)\n",
    "\n",
    "    return (intent_ids, intent_txt, lbl_intent), (qry_ids, qry_txt, qry_intent), intent_info, lbl_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bf302-79ff-468b-92aa-350d23e9ce61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "746a1416-35cd-4591-9122-626ab8381d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_metadata(save_dir:str, intent_ids:List, intent_txt:List, lbl_intent:sp.csr_matrix, \n",
    "                  qry_ids:List, qry_txt:List, qry_intent:sp.csr_matrix):\n",
    "    \n",
    "    n_intent = lbl_intent.shape[1]\n",
    "    \n",
    "    lbl_intent.sum_duplicates()\n",
    "    lbl_intent.sort_indices()\n",
    "    \n",
    "    qry_intent.sum_duplicates()\n",
    "    qry_intent.sort_indices()\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(f\"{save_dir}/raw_data/\", exist_ok=True)\n",
    "    \n",
    "    sp.save_npz(f\"{save_dir}/intent_qry_X_Y.npz\", qry_intent)\n",
    "    save_raw(f\"{save_dir}/raw_data/query.raw.csv\", qry_ids, qry_txt)\n",
    "    \n",
    "    sp.save_npz(f\"{save_dir}/intent_lbl_X_Y.npz\", lbl_intent)\n",
    "    save_raw(f\"{save_dir}/raw_data/label_intent.raw.csv\", intent_ids, intent_txt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f238d1-c8c4-4270-be36-24d3a9ce15ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7544aea1-5fd2-4d6b-9252-1c2086077484",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_metadata_info(save_dir:str, intent_info:Tuple, lbl_info:Tuple):    \n",
    "    (intent_phrase, phrase_vocab), (intent_intents, intents_vocab), (intent_substr, substr_vocab) = intent_info\n",
    "    (lbl_query, query_vocab), (lbl_queries, queries_vocab) = lbl_info\n",
    "    \n",
    "    intent_phrase.sum_duplicates()\n",
    "    intent_phrase.sort_indices()\n",
    "    \n",
    "    intent_intents.sum_duplicates()\n",
    "    intent_intents.sort_indices()\n",
    "\n",
    "    intent_substr.sum_duplicates()\n",
    "    intent_substr.sort_indices()\n",
    "\n",
    "    lbl_query.sum_duplicates()\n",
    "    lbl_query.sort_indices()\n",
    "\n",
    "    lbl_queries.sum_duplicates()\n",
    "    lbl_queries.sort_indices()\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    os.makedirs(f\"{save_dir}/raw_data/\", exist_ok=True)\n",
    "\n",
    "    def get_raw_info(vocab):\n",
    "        txt = sorted(phrase_vocab, key=lambda x: phrase_vocab[x])\n",
    "        ids = list(range(len(txt)))\n",
    "        return ids, txt\n",
    "    \n",
    "    sp.save_npz(f\"{save_dir}/derived-phrases_intent_X_Y.npz\", intent_phrase)\n",
    "    ids, txt = get_raw_info(phrase_vocab)\n",
    "    save_raw(f\"{save_dir}/raw_data/intent_derived-phrases.raw.csv\", ids, txt)\n",
    "    \n",
    "    sp.save_npz(f\"{save_dir}/derived-intents_intent_X_Y.npz\", intent_intents)\n",
    "    ids, txt = get_raw_info(intents_vocab)\n",
    "    save_raw(f\"{save_dir}/raw_data/intent_derived-intents.raw.csv\", ids, txt)\n",
    "\n",
    "    sp.save_npz(f\"{save_dir}/substring_intent_X_Y.npz\", intent_substr)\n",
    "    ids, txt = get_raw_info(substr_vocab)\n",
    "    save_raw(f\"{save_dir}/raw_data/intent_substring.raw.csv\", ids, txt)\n",
    "    \n",
    "    sp.save_npz(f\"{save_dir}/qry_lbl_X_Y.npz\", lbl_query)\n",
    "    ids, txt = get_raw_info(query_vocab)\n",
    "    save_raw(f\"{save_dir}/raw_data/label_query.raw.csv\", ids, txt)\n",
    "\n",
    "    sp.save_npz(f\"{save_dir}/derived-queries_lbl_X_Y.npz\", lbl_queries)\n",
    "    ids, txt = get_raw_info(queries_vocab)\n",
    "    save_raw(f\"{save_dir}/raw_data/label_derived-queries.raw.csv\", ids, txt)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd56853c-4ac3-499d-94b1-edea240878d9",
   "metadata": {},
   "source": [
    "## `Driver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17b032-bdfc-4627-b101-9d0d7370da46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "if __name__ == \"__main__\":\n",
    "    datasets = [\"msmarco\"]\n",
    "    output_dir = \"/Users/suchith720/Downloads/\"\n",
    "\n",
    "    for dataset in tqdm(BEIR_DATASETS):\n",
    "        print(dataset)\n",
    "        \n",
    "        data_dir = f\"/Users/suchith720/Projects/data/beir/{dataset}/XC/\"\n",
    "        lbl_ids, lbl_txt = load_raw_file(f\"{data_dir}/raw_data/label.raw.txt\")\n",
    "\n",
    "        dirname = f\"{output_dir}/{dataset}\"\n",
    "        for dtype in [\"single\", \"multihop\"]:\n",
    "            o = extract_metadata(dirname, dtype, lbl_ids)\n",
    "            (intent_ids, intent_txt, lbl_intent), (qry_ids, qry_txt, qry_intent), intent_info, lbl_info = o\n",
    "    \n",
    "            save_dir = f\"{data_dir}/document_intent_substring/{dtype}\"\n",
    "            save_metadata(save_dir, intent_ids, intent_txt, lbl_intent, qry_ids, qry_txt, qry_intent)\n",
    "            save_metadata_info(save_dir, intent_info, lbl_info)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5adc8-814b-4972-b572-7fed247b64a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09c8c1f3-ebc5-439e-8e08-9735f7065046",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"msmarco\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1b413635-5593-4299-839f-8061cc9a0ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/Users/suchith720/Downloads/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7275eae0-e7fa-41d1-9941-a648842fa629",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a49a3ae-1b18-4657-a823-db2aa09a8404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3fcc2392-d852-42b8-8fdb-5f7110ec5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = f\"/Users/suchith720/Projects/data/beir/{dataset}/XC/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "307b944b-0b4b-43ba-89df-7f705440c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_ids, lbl_txt = load_raw_file(f\"{data_dir}/raw_data/label.raw.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ffe23ebc-6a8b-4b30-83d6-2f88cb19d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = f\"{output_dir}/{dataset}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a95582a-efb8-4c02-bf68-d11c1906f47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "96061087-6e85-4e1a-b755-dfde765d75b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c423beaacb48431ba85265c7d2d08f0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "303f5c72ed334f68bd73fc9f0026f82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8841823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598354c251df4c9b8679af5616edb5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a567517f86434b02bf78fb76b330596f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97afd60adbaa4ad7b615385e60cab1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15764 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64392fe5c2a4e139e5584a0811c9a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8841823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf6374efbe64a0db930b83bc676ecf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8841823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "o = extract_metadata(dirname, \"single\", lbl_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "36d80b9d-b1bb-4b20-b1c9-584a017f39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(intent_ids, intent_txt, lbl_intent), (qry_ids, qry_txt, qry_intent), intent_info, lbl_info = o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10cfcf6-4f50-4116-a4aa-e5892b8f3b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "df091b0e-49ea-48e3-909b-2d7c58eb792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f\"/Users/suchith720/Projects/data/beir/{dataset}/XC/document_intent_substring\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "57d15307-696d-4fd3-87f0-467760414855",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metadata(save_dir, intent_ids, intent_txt, lbl_intent, qry_ids, qry_txt, qry_intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9cd64936-9191-4eed-842b-dbd752dc6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metadata_info(save_dir, intent_info, lbl_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31143c8b-de53-4796-b280-78dc010b3833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc0ae0-4dd4-44b2-8098-b9c82bbbb824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc75180-6c52-45cc-8d48-1f4747a72f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
