# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/10_msmarco-gpt-entities.ipynb.

# %% auto 0
__all__ = ['load_raw_txt', 'select_entity', 'load_entities', 'load_data', 'save_raw_txt', 'construct_matrix',
           'construct_msmarco_entities', 'parse_args']

# %% ../nbs/10_msmarco-gpt-entities.ipynb 2
from tqdm.auto import tqdm
import json, re, scipy.sparse as sp, pickle, numpy as np

# %% ../nbs/10_msmarco-gpt-entities.ipynb 3
def load_raw_txt(fname):
    ids, texts = list(), list()
    with open(fname, 'r') as file:
        for line in file:
            k,v = line[:-1].split("->", maxsplit=1)
            ids.append(int(k)); texts.append(v)
    return ids, texts
    

# %% ../nbs/10_msmarco-gpt-entities.ipynb 4
def select_entity(entities, entity_type='entity_canonical_category'):
    if entity_type == 'entity_canonical_category': return [o.lower() for o in entities if len(o.split(' | ')) == 3]
    elif entity_type == 'entity': return [o.split(' | ')[0].lower() for o in entities if len(o.split(' | ')) == 3]
    elif entity_type == 'canonical': return [o.split(' | ')[1].lower() for o in entities if len(o.split(' | ')) == 3]
    elif entity_type == 'category': return [o.split(' | ')[2].lower() for o in entities if len(o.split(' | ')) == 3]
    elif entity_type == 'entity_canonical': return [' | '.join(o.split(' | ')[0:2]).lower() for o in entities if len(o.split(' | ')) == 3]
    else: raise ValueError(f'Invalid entity type: {entity_type}')
    

# %% ../nbs/10_msmarco-gpt-entities.ipynb 5
def load_entities(fname, entity_type='entity_canonical_category'):
    with open(fname, 'rb') as file:
        generations = pickle.load(file)
    entities = dict()
    for k,v in tqdm(generations.items(), total=len(generations)):
        query = k.split('\t')[1].split('==::==')[0].split('|||')[1]
        entities.setdefault(query, []).extend(select_entity(v['Entities'], entity_type))
    return entities


# %% ../nbs/10_msmarco-gpt-entities.ipynb 6
def load_data(data_dir, entity_dir, entity_type='entity_canonical_category'):
    trn_ids, trn_texts = load_raw_txt(f'{data_dir}/raw_data/train.raw.txt')
    trn_entities = load_entities(f'{entity_dir}/trn_gpt_generations.pkl', entity_type=entity_type)
    trn_data = (trn_ids, trn_texts, trn_entities)

    tst_ids, tst_texts = load_raw_txt(f'{data_dir}/raw_data/test.raw.txt')
    tst_entities = load_entities(f'{entity_dir}/dev_gpt_generations.pkl', entity_type=entity_type)
    tst_data = (tst_ids, tst_texts, tst_entities)

    entity_to_idx = dict()
    for v in trn_entities.values():
        for e in v: entity_to_idx.setdefault(e, len(entity_to_idx))
    for v in tst_entities.values():
        for e in v: entity_to_idx.setdefault(e, len(entity_to_idx))
        
    return trn_data, tst_data, entity_to_idx
        

# %% ../nbs/10_msmarco-gpt-entities.ipynb 7
def save_raw_txt(fname, ids, texts):
    with open(fname, 'w') as file:
        for k,v in tqdm(zip(ids, texts), total=len(ids)):
            file.write(f'{k}->{v}\n')
        

# %% ../nbs/10_msmarco-gpt-entities.ipynb 8
def construct_matrix(texts, entities, entity_to_idx):
    data, indices, indptr = [], [], [0]
    for qtxt in tqdm(texts):
        entity = entities.get(qtxt, [])
        data.extend([1] * len(entity))
        indices.extend([entity_to_idx[o] for o in entity])
        indptr.append(len(indices))
    return sp.csr_matrix((data, indices, indptr), shape=(len(texts), len(entity_to_idx)), dtype=np.int64)


# %% ../nbs/10_msmarco-gpt-entities.ipynb 9
def construct_msmarco_entities(data_dir:str, entity_dir:str, entity_type='entity_canonical_category'):
    trn_data, tst_data, entity_to_idx = load_data(data_dir, entity_dir, entity_type=entity_type)

    entity_texts = sorted(entity_to_idx, key=lambda x: entity_to_idx[x])
    save_raw_txt(f'{data_dir}/raw_data/gpt_{entity_type}.raw.txt', list(range(len(entity_texts))), entity_texts)

    trn_mat = construct_matrix(trn_data[1], trn_data[2], entity_to_idx)
    sp.save_npz(f'{data_dir}/gpt_{entity_type}_trn_X_Y.npz', trn_mat)

    tst_mat = construct_matrix(tst_data[1], tst_data[2], entity_to_idx)
    sp.save_npz(f'{data_dir}/gpt_{entity_type}_tst_X_Y.npz', tst_mat)

    lbl_mat = sp.csr_matrix((sp.load_npz(f'{data_dir}/trn_X_Y.npz').shape[1], len(entity_to_idx)), dtype=np.int64)
    sp.save_npz(f'{data_dir}/gpt_{entity_type}_lbl_X_Y.npz', lbl_mat)
    

# %% ../nbs/10_msmarco-gpt-entities.ipynb 10
def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_dir', type=str, required=True)
    parser.add_argument('--entity_dir', type=str, required=True)
    parser.add_argument('--entity_type', type=str, required=True)
    return parser.parse_args()
    

# %% ../nbs/10_msmarco-gpt-entities.ipynb 11
if __name__ == '__main__':
    args = parse_args()
    construct_msmarco_entities(args.data_dir, args.entity_dir, args.entity_type)
