# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/21_beir-dataset.ipynb.

# %% auto 0
__all__ = ['download_mteb', 'load_queries', 'load_labels', 'load_qrels', 'get_matrix', 'QueryInfo', 'LabelInfo', 'get_dataset',
           'save_dataset', 'sample_dataset', 'get_and_save_dataset', 'parse_args']

# %% ../nbs/21_beir-dataset.ipynb 2
import os, json, pandas as pd, scipy.sparse as sp, numpy as np, argparse

from tqdm.auto import tqdm
from datasets import load_dataset
from dataclasses import dataclass
from huggingface_hub import snapshot_download

from .core import *

# %% ../nbs/21_beir-dataset.ipynb 4
def download_mteb(dset:str, data_dir=None):
    if not os.path.exists(data_dir): os.makedirs(data_dir, exist_ok=True)
    snapshot_download(repo_id=f"mteb/{dset}", repo_type="dataset", local_dir=data_dir)
    

# %% ../nbs/21_beir-dataset.ipynb 8
def load_queries(fname):
    queries = dict()
    with open(fname, 'r') as file:
        for line in file:
            data = json.loads(line)
            queries[data['_id']] = data['text']
    return queries
        

# %% ../nbs/21_beir-dataset.ipynb 9
def load_labels(fname):
    labels, lid_to_idx = [], dict()
    with open(fname, 'r') as file:
        for idx,line in enumerate(file):
            data = json.loads(line)
            lid_to_idx[data['_id']] = idx
            labels.append(data['text'])
    return labels, lid_to_idx
        

# %% ../nbs/21_beir-dataset.ipynb 10
def load_qrels(fname, lbl_id2idx=None):
    qrels = pd.read_table(fname)
    assert (qrels['score'] == 1).all(), 'Score should contain all 1s'

    query_to_labels = dict()
    for qid, lid in tqdm(zip(qrels['query-id'], qrels['corpus-id']), total=qrels.shape[0]):
        query_to_labels.setdefault(qid, []).append(lid if lbl_id2idx is None else lbl_id2idx[lid])

    return query_to_labels
    

# %% ../nbs/21_beir-dataset.ipynb 17
def get_matrix(fname, lbl_id2idx):
    mapping = load_qrels(fname, lbl_id2idx)
    return get_matrix_from_item2idx(mapping, len(lbl_id2idx))
    

# %% ../nbs/21_beir-dataset.ipynb 18
@dataclass
class QueryInfo:
    mat: sp.csr_matrix
    ids: list
    txt: list

    def sample_labels(self, lbl_idx:list):
        data_idx = np.where(self.mat.getnnz(axis=1) > 0)[0]
        
        self.mat = self.mat[:, lbl_idx][data_idx, :]
        self.ids = [self.ids[i] for i in data_idx]
        self.txt = [self.txt[i] for i in data_idx]

@dataclass
class LabelInfo:
    ids: list
    txt: list

    def sample(self, valid_idx:list):
        self.ids = [self.ids[i] for i in valid_idx]
        self.txt = [self.txt[i] for i in valid_idx]
    

# %% ../nbs/21_beir-dataset.ipynb 19
def get_dataset(query_file:str, lbl_file:str, tst_file:str, trn_file:str=None):
    queries = load_queries(query_file)
    
    lbl_txt, lbl_id2idx = load_labels(lbl_file)
    lbl_ids = sorted(lbl_id2idx, key=lambda x: lbl_id2idx[x])
    lbl_info = LabelInfo(lbl_ids, lbl_txt)
    
    tst_mat, tst_ids = get_matrix(tst_file, lbl_id2idx)
    tst_txt = [queries[o] for o in tst_ids]
    tst_info = QueryInfo(tst_mat, tst_ids, tst_txt)

    if trn_file is not None:
        trn_mat, trn_ids = get_matrix(trn_file, lbl_id2idx)
        trn_txt = [queries[o] for o in trn_ids]
        trn_info = QueryInfo(trn_mat, trn_ids, trn_txt)
        return trn_info, tst_info, lbl_info
        
    return None, tst_info, lbl_info
    

# %% ../nbs/21_beir-dataset.ipynb 20
def save_dataset(save_dir, tst_info, lbl_info, trn_info=None, suffix=''):
    os.makedirs(save_dir, exist_ok=True)
    x_suffix = f'_{suffix}' if len(suffix) else ''

    if trn_info is not None: sp.save_npz(f'{save_dir}/trn_X_Y{x_suffix}.npz', trn_info.mat)
    sp.save_npz(f'{save_dir}/tst_X_Y{x_suffix}.npz', tst_info.mat)
    
    os.makedirs(f'{save_dir}/raw_data', exist_ok=True)
    y_suffix = f'.{suffix}' if len(suffix) else ''
    if trn_info is not None: save_raw_file(f'{save_dir}/raw_data/train.raw.csv', trn_info.ids, trn_info.txt)
    save_raw_file(f'{save_dir}/raw_data/test.raw.csv', tst_info.ids, tst_info.txt)
    save_raw_file(f'{save_dir}/raw_data/label{y_suffix}.raw.csv', lbl_info.ids, lbl_info.txt)
    

# %% ../nbs/21_beir-dataset.ipynb 21
def sample_dataset(tst_info, lbl_info, trn_info=None, sampling_type=None):
    if sampling_type == 'exact':
        valid_idx = np.where(trn_info.mat.getnnz(axis=0) > 0)[0] if trn_info is None else np.array([], dtype=tst_info.mat.dtype)
        tst_valid_idx = np.where(tst_info.mat.getnnz(axis=0) > 0)[0]
        valid_idx = np.union1d(trn_valid_idx, tst_valid_idx)
    elif sampling_type == 'xc':
        valid_idx = np.where(trn_info.mat.getnnz(axis=0) > 0)[0]
    else:
        raise ValueError(f'Invalid sampling value: {sampling_type}.')
            
    trn_info.sample_labels(valid_idx)
    tst_info.sample_labels(valid_idx)
    lbl_info.sample(valid_idx)
    

# %% ../nbs/21_beir-dataset.ipynb 22
def get_and_save_dataset(query_file:str, lbl_file:str, tst_file:str, trn_file:str=None, save_dir:str=None, sampling_type=None, suffix=''):
    trn_info, tst_info, lbl_info = get_dataset(query_file, lbl_file, tst_file, trn_file)
    if sampling_type is not None: sample_dataset(tst_info, lbl_info, trn_info, sampling_type)
    if save_dir is not None: save_dataset(save_dir, tst_info, lbl_info, trn_info, suffix)
    return trn_info, tst_info, lbl_info
    

# %% ../nbs/21_beir-dataset.ipynb 23
def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--download', action='store_true')
    parser.add_argument('--dataset', type=str)
    
    parser.add_argument('--data_dir', type=str, required=True)
    parser.add_argument('--save_dir', type=str)
    
    return parser.parse_args()
    

# %% ../nbs/21_beir-dataset.ipynb 24
if __name__ == '__main__':
    args = parse_args()
    if args.download: 
        download_mteb(args.dataset, args.data_dir)
    else:
        get_and_save_dataset(f'{args.data_dir}/queries.jsonl', f'{args.data_dir}/corpus.jsonl', f'{args.data_dir}/qrels/test.tsv', 
                             save_dir=args.save_dir)
                          
