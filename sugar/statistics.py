# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/12_dataset-statistics.ipynb.

# %% auto 0
__all__ = ['METADATA_CODE', 'CODE_METADATA', 'UpdatedDataset', 'Dataset', 'matrix_stats', 'main_dset_stats', 'meta_dset_stats',
           'dset_stats', 'trn_tst_stats', 'print_stats', 'print_dset_stats', 'TextDataset', 'show_updated_dataset',
           'show_dataset']

# %% ../nbs/12_dataset-statistics.ipynb 2
import scipy.sparse as sp, re, xclib.data.data_utils as du, numpy as np, pandas as pd, os
from IPython.display import display
from torch.utils.data import Dataset
from termcolor import colored, COLORS

from .core import *
from xcai.data import *

# %% ../nbs/12_dataset-statistics.ipynb 4
METADATA_CODE = {'category': 'cat', 'see_also': 'sal', 'hyper_link': 'hlk', 'videos': 'vid', 'images': 'img', 
                 'entity': 'ent', 'canonical': 'can', 'entity_canonical_category': 'ecc', 'entity_canonical': 'enc'}

# %% ../nbs/12_dataset-statistics.ipynb 5
class UpdatedDataset:

    @staticmethod
    def load_data_info(data_dir, type, suffix=''):
        if len(suffix): suffix = f'.{suffix}'
        ids, txt = load_raw_file(f'{data_dir}/raw_data/{type}{suffix}.raw.csv')
        return {'identifier':ids, 'input_text':txt}

    @staticmethod
    def load_lbl_info(data_dir, x_prefix, y_prefix):
        ids, txt = load_raw_file(f'{data_dir}/raw_data/label.{x_prefix}-{y_prefix}.raw.csv')
        return {'identifier':ids, 'input_text':txt}

    @staticmethod
    def load_metadata_info(data_dir, metadata_type, x_prefix, y_prefix, z_prefix):
        ids, txt = load_raw_file(f'{data_dir}/raw_data/{metadata_type}.{x_prefix}-{y_prefix}-{z_prefix}.raw.csv')
        return {'identifier':ids, 'input_text':txt}

    @staticmethod
    def get_trn_tst_info(data_dir, suffix=''):
        trn_info = UpdatedDataset.load_data_info(data_dir, 'train', suffix)
        tst_info = UpdatedDataset.load_data_info(data_dir, 'test', suffix)
        return trn_info, tst_info

    @staticmethod
    def get_labels(data_dir, x_prefix, y_prefix, old_dir=None):
        if x_prefix == 'old' and y_prefix == 'old':
            trn_mat = du.read_sparse_file(f'{old_dir}/trn_X_Y.txt')
            tst_mat = du.read_sparse_file(f'{old_dir}/tst_X_Y.txt')
        else:
            trn_mat = sp.load_npz(f'{data_dir}/trn_X_Y_{x_prefix}-{y_prefix}.npz')
            tst_mat = sp.load_npz(f'{data_dir}/tst_X_Y_{x_prefix}-{y_prefix}.npz')
        
        lbl_info = UpdatedDataset.load_lbl_info(data_dir, x_prefix=x_prefix, y_prefix=y_prefix)
        
        return trn_mat, tst_mat, lbl_info

    @staticmethod
    def get_metadata(data_dir, metadata_type, x_prefix, y_prefix, z_prefix, old_dir=None):
        if x_prefix == 'old' and y_prefix == 'old' and z_prefix == 'old':
            trn_mat = du.read_sparse_file(f'{old_dir}/{metadata_type}_trn_X_Y.txt')
            tst_mat = du.read_sparse_file(f'{old_dir}/{metadata_type}_tst_X_Y.txt')
            lbl_mat = du.read_sparse_file(f'{old_dir}/{metadata_type}_lbl_X_Y.txt')
        else:
            trn_mat = sp.load_npz(f'{data_dir}/{metadata_type}_trn_X_Y_{x_prefix}-{y_prefix}-{z_prefix}.npz')
            tst_mat = sp.load_npz(f'{data_dir}/{metadata_type}_tst_X_Y_{x_prefix}-{y_prefix}-{z_prefix}.npz')
            lbl_mat = sp.load_npz(f'{data_dir}/{metadata_type}_lbl_X_Y_{x_prefix}-{y_prefix}-{z_prefix}.npz')
        
        meta_info = UpdatedDataset.load_metadata_info(data_dir, metadata_type, x_prefix, y_prefix, z_prefix)
        
        return trn_mat, tst_mat, lbl_mat, meta_info

    @staticmethod
    def load_datasets(data_dir, save_dir, metadata_type, x_prefix, y_prefix, z_prefix):
        trn_info, tst_info = UpdatedDataset.get_trn_tst_info(save_dir, x_prefix)
        trn_mat, tst_mat, lbl_info = UpdatedDataset.get_labels(save_dir, x_prefix, y_prefix, data_dir)
    
        main_trn_dset = MainXCDataset(trn_info, trn_mat, lbl_info)
        main_tst_dset = MainXCDataset(tst_info, tst_mat, lbl_info)
    
        trn_meta_mat, tst_meta_mat, lbl_meta_mat, meta_info = UpdatedDataset.get_metadata(save_dir, metadata_type, x_prefix, y_prefix, z_prefix, data_dir)
    
        trn_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], trn_meta_mat, lbl_meta_mat, meta_info)
        tst_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], tst_meta_mat, lbl_meta_mat, meta_info)
    
        trn_dset = XCDataset(main_trn_dset, cat_meta=trn_meta_dset)
        tst_dset = XCDataset(main_tst_dset, cat_meta=tst_meta_dset)
    
        return trn_dset, tst_dset
        

# %% ../nbs/12_dataset-statistics.ipynb 7
class Dataset:

    @staticmethod
    def load_data_lbl_info(data_dir, type):
        if os.path.exists(f'{data_dir}/raw_data/{type}.raw.txt'):
            ids, txt = load_raw_file(f'{data_dir}/raw_data/{type}.raw.txt', encoding='latin-1')
        else:
            ids, txt = load_raw_file(f'{data_dir}/raw_data/{type}.raw.csv')
        return {'identifier':ids, 'input_text':txt}

    @staticmethod
    def load_metadata_info(data_dir, metadata_type, suffix=''):
        if len(suffix): suffix = f'.{suffix}'
        ids, txt = load_raw_txt(f'{data_dir}/raw_data/{metadata_type}{suffix}.raw.csv')
        return {'identifier':ids, 'input_text':txt}

    @staticmethod
    def get_trn_tst_info(data_dir):
        trn_info = Dataset.load_data_lbl_info(data_dir, 'train')
        tst_info = Dataset.load_data_lbl_info(data_dir, 'test')
        return trn_info, tst_info

    @staticmethod
    def get_labels(data_dir):
        trn_mat = du.read_sparse_file(f'{data_dir}/trn_X_Y.txt') if os.path.exists(f'{data_dir}/trn_X_Y.txt') else sp.load_npz(f'{data_dir}/trn_X_Y.npz')
        tst_mat = du.read_sparse_file(f'{data_dir}/tst_X_Y.txt') if os.path.exists(f'{data_dir}/tst_X_Y.txt') else sp.load_npz(f'{data_dir}/tst_X_Y.npz')
            
        lbl_info = Dataset.load_data_lbl_info(data_dir, 'label')
        
        return trn_mat, tst_mat, lbl_info

    @staticmethod
    def get_metadata(data_dir, metadata_type, suffix=''):
        m_suffix = f'_{suffix}' if len(suffix) else suffix
        trn_mat = sp.load_npz(f'{data_dir}/{metadata_type}_trn_X_Y{m_suffix}.npz')
        tst_mat = sp.load_npz(f'{data_dir}/{metadata_type}_tst_X_Y{m_suffix}.npz')
        lbl_mat = sp.load_npz(f'{data_dir}/{metadata_type}_lbl_X_Y{m_suffix}.npz')
        
        meta_info = Dataset.load_metadata_info(data_dir, metadata_type, suffix)
        
        return trn_mat, tst_mat, lbl_mat, meta_info

    @staticmethod
    def load_datasets(data_dir, metadata_type, suffix=''):
        trn_info, tst_info = Dataset.get_trn_tst_info(data_dir)
        trn_mat, tst_mat, lbl_info = Dataset.get_labels(data_dir)
    
        main_trn_dset = MainXCDataset(trn_info, trn_mat, lbl_info)
        main_tst_dset = MainXCDataset(tst_info, tst_mat, lbl_info)
    
        trn_meta_mat, tst_meta_mat, lbl_meta_mat, meta_info = Dataset.get_metadata(data_dir, metadata_type, suffix)
    
        trn_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], trn_meta_mat, lbl_meta_mat, meta_info)
        tst_meta_dset = MetaXCDataset(METADATA_CODE[metadata_type], tst_meta_mat, lbl_meta_mat, meta_info)
    
        trn_dset = XCDataset(main_trn_dset, cat_meta=trn_meta_dset)
        tst_dset = XCDataset(main_tst_dset, cat_meta=tst_meta_dset)
    
        return trn_dset, tst_dset
        

# %% ../nbs/12_dataset-statistics.ipynb 9
CODE_METADATA = {'cat':'Category', 'sal':'Seealso', 'hlk':'hyperlink', 'vid':'Videos', 'img':'Images', 
                 'ent':'Entity', 'can':'Canonical', 'ecc':'Entity Canonical Category', 'enc':'Entity Canonical'}

# %% ../nbs/12_dataset-statistics.ipynb 10
def matrix_stats(mat):
    n_dat = mat.shape[0]
    n_lbl = mat.shape[1]

    num_dat_lbl = mat.getnnz(axis=0)
    num_lbl_dat = mat.getnnz(axis=1)

    avg_dat_lbl = num_dat_lbl.mean()
    avg_lbl_dat = num_lbl_dat.mean()

    max_dat_lbl = num_dat_lbl.max()
    max_lbl_dat = num_lbl_dat.max()

    zro_dat_lbl = np.sum(num_dat_lbl == 0)
    zro_lbl_dat = np.sum(num_lbl_dat == 0)

    stats_dict = {
        f'# Entries' : n_dat,
        f'# Features': n_lbl,
        f'Avg. Entries per feature' : avg_dat_lbl,
        f'Avg. Feature per entry'   : avg_lbl_dat,
        f'Max. Entries per feature' : max_dat_lbl,
        f'Max. Feature per entry'   : max_lbl_dat,
        f'# Features without entry' : zro_dat_lbl,
        f'# Entries without feature': zro_lbl_dat,
    }
    return stats_dict
    

# %% ../nbs/12_dataset-statistics.ipynb 11
def main_dset_stats(dset):
    return matrix_stats(dset.data_lbl)
    

# %% ../nbs/12_dataset-statistics.ipynb 12
def meta_dset_stats(dset):
    dat_stats = matrix_stats(dset.data_meta)
    dat_stats['Dataset'] = 'Query'
    
    lbl_stats = matrix_stats(dset.lbl_meta)
    lbl_stats['Dataset'] = 'Label'

    return [dat_stats, lbl_stats]
    

# %% ../nbs/12_dataset-statistics.ipynb 13
def dset_stats(dset):
    stats = []
    
    main_stats = main_dset_stats(dset.data)
    main_stats['Dataset'] = 'Main'
    stats.append(main_stats)

    for o in dset.meta.values():
        meta_stats = meta_dset_stats(o)
        for s in meta_stats: s['Dataset'] = f'{s["Dataset"]} {CODE_METADATA[o.prefix]} Metadata'
        stats.extend(meta_stats)

    return stats
    

# %% ../nbs/12_dataset-statistics.ipynb 14
def trn_tst_stats(trn_dset, tst_dset):
    trn_stats = dset_stats(trn_dset)
    for o in trn_stats: o['Split'] = 'Train'

    tst_stats = dset_stats(tst_dset)
    for o in tst_stats: o['Split'] = 'Test'

    stats = trn_stats + tst_stats
    return stats
    

# %% ../nbs/12_dataset-statistics.ipynb 15
def print_stats(stats):
    df = pd.DataFrame(stats).set_index(['Split', 'Dataset'])
    with pd.option_context('display.precision', 2):
        display(df)
    

# %% ../nbs/12_dataset-statistics.ipynb 16
def print_dset_stats(trn_dset, tst_dset):
    stats = trn_tst_stats(trn_dset, tst_dset)
    print_stats(stats)
    

# %% ../nbs/12_dataset-statistics.ipynb 18
class TextDataset(Dataset):
    
    def __init__(self, dset, pattern='.*_text$'):
        self.dset, self.pattern = dset, pattern
        colors = list(COLORS.keys())
        self.colors = [colors[i] for i in np.random.permutation(len(colors))]
    
    def __getitem__(self, idx):
        o = self.dset[idx]
        return {k:v for k,v in o.items() if re.match(self.pattern, k)}

    def show(self, idxs):
        for idx in idxs:
            for i,(k,v) in enumerate(self[idx].items()):
                key = colored(k, self.colors[i], attrs=["reverse", "blink"])
                value = colored(f': {v}', self.colors[i])
                print(key, value)
            print()

    def get_head_data(self, topk=10):
        return np.argsort(self.dset.data.data_lbl.getnnz(axis=1))[:-topk:-1]

    def get_tail_data(self, topk=10):
        num = self.dset.data.data_lbl.getnnz(axis=1)
        idx = np.argsort(num)
        valid = (num > 0)[idx]
        return idx[valid][:topk]
        
    def dump_txt(self, fname, idxs):
        with open(fname, 'w') as file:
            for idx in idxs:
                for i,(k,v) in enumerate(self[idx].items()):
                    file.write(f'{k}: {v}\n')
                file.write('\n')
            
    def dump_csv(self, fname, idxs):
        df = pd.DataFrame([self[idx] for idx in idxs])
        df.to_csv(fname, index=False)

    def dump(self, fname, idxs):
        if fname.endswith('.txt'): 
            self.dump_txt(fname, idxs)
        elif fname.endswith('.csv'): 
            self.dump_csv(fname, idxs)
        else: 
            raise ValueError(f'Invalid file extension: {fname}')
        
    

# %% ../nbs/12_dataset-statistics.ipynb 20
def show_updated_dataset(data_dir, save_dir, metadata_type, x_prefix, y_prefix, z_prefix, idxs, use_trn=True):
    trn_dset, tst_dset = UpdatedDataset.load_datasets(data_dir, save_dir, metadata_type, x_prefix, y_prefix, z_prefix)
    print_dset_stats(trn_dset, tst_dset)
    
    txt_dset = TextDataset(trn_dset if use_trn else tst_dset)
    txt_dset.show(idxs)
    
    return trn_dset, tst_dset

def show_dataset(data_dir, metadata_type, idxs, suffix='', use_trn=True):
    trn_dset, tst_dset = Dataset.load_datasets(data_dir, metadata_type, suffix=suffix)
    print_dset_stats(trn_dset, tst_dset)
    
    txt_dset = TextDataset(trn_dset if use_trn else tst_dset)
    txt_dset.show(idxs)
    
    return trn_dset, tst_dset
    
